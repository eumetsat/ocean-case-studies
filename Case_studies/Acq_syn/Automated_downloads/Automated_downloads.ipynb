{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2024 European Union <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\"><img src=\"https://img.shields.io/badge/open-EUMETLAB-E67E22.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://user.eumetsat.int/data/themes/marine\"><img src=\"https://img.shields.io/badge/open-USER PORTAL-154360.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-case-studies/HEAD?labpath=Case_studies%2FAcq_syn%2FAutomated_downloads%2FAutomated_downloads.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads/Automated_downloads.ipynb\"><img src=\"https://img.shields.io/badge/launch-WEKEO-1a4696.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://code.insula.destine.eu/hub/\"><img src=\"https://img.shields.io/badge/launch-DestinE-f43fd3.svg\"></a></div></div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean case studies</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "This notebook has the following prerequisites:\n",
    "- **<a href=\"https://eoportal.eumetsat.int/\" target=\"_blank\">A EUMETSAT Earth Observation Portal account</a>** to download from the EUMETSAT Data Store\n",
    "\n",
    "There are no prerequisite notebooks for this module.<br>\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated downloading of EUMETSAT marine products\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Dataset | EUMETSAT Data Store<br>collection ID| EUMETSAT collection<br>description | WEkEO dataset ID | WEkEO description |\n",
    "|:--------------------:|:-----------------------:|:-------------:|:-----------------:|:-----------------:|\n",
    "| Sentinel-3 SLSTR level-2P | EO:EUM:DAT:0412 | <a href=\"https://user.eumetsat.int/catalogue/EO:EUM:DAT:0179\" target=\"_blank\">Description</a> | EO:EUM:DAT:SENTINEL-3:SL_2_WST___ | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AEUM%3ADAT%3ASENTINEL-3%3ASL_2_WST___&initial=1\" target=\"_blank\">Description</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know how to;\n",
    "* Access EUMETSAT Copernicus marine products from the EUMETSAT Data Store\n",
    "* Construct a search query to match the data we want\n",
    "* Automate this search query to constantly gather new data\n",
    "\n",
    "### Outline\n",
    "\n",
    "<center><img src='https://www.pmel.noaa.gov/gtmba/sites/default/files/styles/landing_page_banner/public/thumbnails/image/IMG_0622.jpg?itok=2kbeXv8z&c=50259841db4e6fd909aea30cc0b86551\n",
    "' align='center' width='750px' height=\"800px\"/>\n",
    "<img src='http://www.pmel.noaa.gov/pirata/global_pirata_web_sm.gif' align='center' width='500px' height=\"300px\"/><br>Figure 1: The Atlantic monitoring <a href=\"https://www.brest.ird.fr/pirata/\" target=\"_blank\">PIRATA</a> branch of the <a href=\"https://www.pmel.noaa.gov/gtmba/\" target=\"_blank\">Global Tropical Moored Buoy Array (GTMBA)</a> (Credit: PMEL)</center><br><br>\n",
    "\n",
    "It is fairly common for us to want to work with the newest satellite data available. We do this, for example, when we want to monitor a region in near real-time, or when we want to compare against *in situ* platforms that are continually acquiring, e.g. a mooring. The first step in most of these activities is to automate data acquisition, allowing us to download the newest data available with no intervention.\n",
    "\n",
    "In this notebook, we are going to download near real-time sea surface temperature products from the Sentinel-3 Sea and Land Surface Temperature Radiometer (SLSTR) when they correspond to one of the moorings in the <a href=\"https://www.brest.ird.fr/pirata/\" target=\"_blank\">PIRATA</a> array, a series of moorings that make up the Atlantic branch of the Global Tropical Moored Buoy Array (GTMBA) (Figure 1). We will introduce methods to do this using an entirely Pythoon-based approach, and using external system tools such as *cron* on Linux/OSx and *ScheduledTasks* on Windows.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOCTOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "\n",
    " 1. [Step 1: Setting up our analysis](#section1)\n",
    " 1. [Step 2: Authenticating the EUMETSAT Data Store](#section2)\n",
    " 1. [Step 3: Selecting data from the EUMETSAT Data Store](#section3)\n",
    " 1. [Step 4: Automating downloading within Python](#section4)\n",
    " 1. [Step 5: Automating downloading outside of Python](#section5)\n",
    " 1. [Step 6: Conclusions](#section6)\n",
    " 1. [Step 7: Challenge (optional)](#section7)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Setting up our analysis\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing all of the libraries that we need to run this notebook. If you have built your python using the environment file provided in this repository, then you should have everything you need. For more information on building environment, please see the repository **<a href=\"../../../README.md\" target=\"_blank\">README</a>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime                           # a library that allows us to work with dates and times\n",
    "import eumdac                             # a tool that helps us download via the eumetsat/data-store\n",
    "import getpass                            # a library to help us enter passwords\n",
    "import os                                 # a library that allows us access to basic operating system commands\n",
    "from pathlib import Path                  # a library to help us to construct system paths\n",
    "import schedule                           # a library to help us to schedule tasks\n",
    "import shutil                             # a library that allows us access to basic operating system commands like copy\n",
    "import subprocess                         # a library to help us to run system commands\n",
    "import sys                                # a library that gives us access to system tools\n",
    "import time                               # a library that helps us manage script timing\n",
    "import warnings                           # a library that helps us handle warnings\n",
    "\n",
    "# turn off any script warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by setting a few parameters that we will need for our experiment, beginning with the location of one of the PIRATA moorings (in this case the most North Easterly) and the size of the box we want to acquire around this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIRATA mooring location\n",
    "lat = 21\n",
    "lon = -23\n",
    "\n",
    "# size of the box we want to acquire around the location of interest\n",
    "spatial_tolerance = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets specify the collections of interest that contain our data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionID = \"EO:EUM:DAT:0412\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from Sentinel-3 is available at various timeliness. Near real-time data (NR) is available quickly, but does not have the highest quality. Non time-critical data (NT) is available more slowly, but is higher quality. We want the most up to date data, so we will focus on the NR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeliness = \"NR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets set a few parameters that help us with automating our acquisition; the number of days before today we want to limit our search to (`days_ago`), the format we want any time variables to be in (`tformat`) and how often to run our search (`n_seconds`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_ago = 5\n",
    "tformat = '%Y-%m-%dT%H:%M:%S'\n",
    "nseconds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to begin gathering our data for analysis, beginning by authenticating our access to the EUMETSAT Data Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Authenticating the EUMETSAT Data Store\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing the EUMETSAT Data Store\n",
    "\n",
    "To access Copernicus marine data from the <a href=\"https://data.eumetsat.int \" target=\"_blank\">EUMETSAT Data Store</a>, we will use the EUMETSAT Data Access Client (`eumdac`) python package. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install eumdac using;\n",
    "\n",
    "`conda install -c eumetsat eumdac`\n",
    "\n",
    "You can also find the source code on the <a href=\"https://gitlab.eumetsat.int/eumetlab/data-services/eumdac \" target=\"_blank\">EUMETSAT GitLab</a>. Please visit the EUMETSAT user portal for more information on the <a href=\"https://user.eumetsat.int/data-access/data-store \" target=\"_blank\">EUMETSAT Data Store</a> and <a href=\"https://user.eumetsat.int/resources/user-guides/eumetsat-data-access-client-eumdac-guide \" target=\"_blank\">eumdac</a>.\n",
    "\n",
    "To download data from the EUMETSDAT Data Store via API, you need to provide credentials. To obtain these you should first register at for an <a href=\"https://eoportal.eumetsat.int/\" target=\"_blank\">EUMETSAT Earth Observation Portal account</a>. Once you have an account, you can retrieve your `<your_consumer_key>` and `<your_consumer_secret>` from the <a href=\"https://api.eumetsat.int/api-key/ \" target=\"_blank\">\"EUMETSAT Data Store API\"</a> page (*Note: you must click the \"Show hidden fields\" button at the bottom of the page to see the relevant fields*). If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: your key and secret are permanent, so you should take care to never share them*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This token '07d0918b-de20-3b1d-80e4-c3305446bb1a' expires 2024-04-30 15:50:37.977822\n"
     ]
    }
   ],
   "source": [
    "# load credentials\n",
    "eumdac_credentials_file = Path(Path.home() / '.eumdac' / 'credentials')\n",
    "\n",
    "if os.path.exists(eumdac_credentials_file):\n",
    "    consumer_key, consumer_secret = Path(eumdac_credentials_file).read_text().split(',')\n",
    "else:\n",
    "    # creating authentication file\n",
    "    consumer_key = input('Enter your consumer key: ')\n",
    "    consumer_secret = getpass.getpass('Enter your consumer secret: ')\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(eumdac_credentials_file), exist_ok=True)\n",
    "        with open(eumdac_credentials_file, \"w\") as f:\n",
    "            f.write(f'{consumer_key},{consumer_secret}')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "token = eumdac.AccessToken((consumer_key, consumer_secret))\n",
    "print(f\"This token '{token}' expires {token.expiration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a token, we can create an instance of the EUMETSAT Data Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = eumdac.DataStore(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Selecting data from the EUMETSAT Data Store\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have authenticated our `datastore` object, lets connect to the collection we are interested in using the `get_collection` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use collection ID\n",
    "collection = datastore.get_collection(collectionID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now search in our collection, filtering our search by the specified `timeliness`, our region of interest and the number of days before now (`days_ago`) and today. We can do this as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a very small box around our proposed mooring\n",
    "ROI = [[lon - spatial_tolerance, lat - spatial_tolerance],\n",
    "       [lon - spatial_tolerance, lat + spatial_tolerance],\n",
    "       [lon + spatial_tolerance, lat + spatial_tolerance],\n",
    "       [lon + spatial_tolerance, lat - spatial_tolerance],\n",
    "       [lon - spatial_tolerance, lat - spatial_tolerance]]\n",
    "\n",
    "# convert this to a WKT polygon\n",
    "polygon = 'POLYGON(({}))'.format(','.join([\"{} {}\".format(*coord) for coord in ROI]))\n",
    "\n",
    "# make a very small time window around our cruise point time\n",
    "dtend = datetime.datetime.now()\n",
    "dtstart = dtend - datetime.timedelta(days=days_ago)\n",
    "products = collection.search(dtstart=dtstart, dtend=dtend, geo=polygon, timeliness=timeliness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how many products we found..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3\n",
      "\n",
      "----\n",
      "Found 15 products\n"
     ]
    }
   ],
   "source": [
    "for product in products:\n",
    "    print(str(product))\n",
    "print(f\"\\n----\\nFound {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>4. Automating downloading **within Python**\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, but we have only made a single query! To automate this, we need to;\n",
    "* provide a way to schedule the search and download process in time, and\n",
    "* a way to update the start and end dates for the acquisition\n",
    "\n",
    "Fortunately, this is quite easy to do in Python using the `Schedule` library (imported above). `Schedule` will run a function on any time base you specify. Lets go ahead and build our function, which we will call `automate_run`.\n",
    "\n",
    "`automate_run` takes the search query we ran above, and adds a download component to it. It accepts a number of arguments (`token`, `collectionID`, `polygon`, `timeliness`, `days_ago`) that allow up to update it on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_run(token, collectionID, polygon, timeliness, days_ago):\n",
    "    '''\n",
    "     A function to download specified products from the EUMETSAT Data Store\n",
    "    '''\n",
    "    # instantiate the datastore\n",
    "    datastore = eumdac.DataStore(token)\n",
    "    \n",
    "    # select collection\n",
    "    collection = datastore.get_collection(collectionID)\n",
    "    \n",
    "    # set parameters\n",
    "    dtend = datetime.datetime.now()\n",
    "    dtstart = dtend - datetime.timedelta(days=days_ago)\n",
    "    \n",
    "    print(\"----------Downloads starting----------\")\n",
    "    print(f\"Start date: {dtstart.strftime(tformat)}\\nEnd date: {dtend.strftime(tformat)}\")\n",
    "    \n",
    "    # search for the specified products\n",
    "    products = collection.search(dtstart=dtstart, dtend=dtend, geo=polygon, timeliness=timeliness)\n",
    "\n",
    "    # download the specified products\n",
    "    for product in products:\n",
    "        product_zip = os.path.join(os.getcwd(), str(product) + '.zip')\n",
    "        if os.path.exists(product_zip):\n",
    "            print(f'Skipping {str(product)} (exists)')\n",
    "        else:\n",
    "            with product.open() as fsrc, open(fsrc.name, mode='wb') as fdst:\n",
    "                print(f'Downloading {fsrc.name}.')\n",
    "                shutil.copyfileobj(fsrc, fdst)\n",
    "    \n",
    "    print(\"----------Downloads complete----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `automate_run` function is defined, but we are not yet running it. To set things up, we launch it via `schedule`. In the cell below, we set up `schedule` to run every `nseconds` (which we defined above as 10 by default), providing our function name and arguments.\n",
    "\n",
    "Once it is set up, we start an \"infinite\" `while` loop that will continually run downloading new data as it appears in the Data Store (and backfilling everything we delete that falls within scope!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:29:01\n",
      "End date: 2024-04-30T15:29:01\n",
      "Downloading S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3.zip.\n",
      "Downloading S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3.zip.\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:30:34\n",
      "End date: 2024-04-30T15:30:34\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:30:44\n",
      "End date: 2024-04-30T15:30:44\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:30:55\n",
      "End date: 2024-04-30T15:30:55\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:31:06\n",
      "End date: 2024-04-30T15:31:06\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:31:16\n",
      "End date: 2024-04-30T15:31:16\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:31:27\n",
      "End date: 2024-04-30T15:31:27\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:31:37\n",
      "End date: 2024-04-30T15:31:37\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:31:48\n",
      "End date: 2024-04-30T15:31:48\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Downloading S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3.zip.\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n",
      "----------Downloads starting----------\n",
      "Start date: 2024-04-25T15:32:04\n",
      "End date: 2024-04-30T15:32:04\n",
      "Skipping S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3 (exists)\n",
      "Skipping S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3 (exists)\n",
      "----------Downloads complete----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      8\u001b[0m     schedule\u001b[38;5;241m.\u001b[39mrun_pending()\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "schedule.every(nseconds).seconds.do(automate_run,\n",
    "                                    token=token,\n",
    "                                    collectionID=collectionID,\n",
    "                                    polygon=polygon,\n",
    "                                    timeliness=timeliness,\n",
    "                                    days_ago=days_ago)\n",
    "while 1:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You automated job is now running! However, you must keep Python open to keep it so. If you wish to clear the jobs, you can do so using the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the job, when completed\n",
    "schedule.clear()\n",
    "schedule.cancel_job(automate_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is simple, compartmentalised and does not require any additional authentication. However it has some major drawbacks in that;\n",
    "\n",
    "1. it only runs in the context of this notebook, which is not as stable as a system environment\n",
    "2. it requires all of the Python dependencies that we provide with this environment\n",
    "3. there is no logging if something goes wrong!\n",
    "\n",
    "A better strategy would be to take advantage of the `eumdac` command line interface (CLI) to schedule the task using common system tools. This is what we will explore next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>5.  Automating downloading **outside of Python**\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data access and download commands we have constructed using the `eumdac` Python library, can be replicated using the `eumdac` command line interface (CLI). You can find more information on using the CLI on our <a href=\"https://user.eumetsat.int/resources/user-guides/eumetsat-data-access-client-eumdac-guide\" target=\"_blank\">EUMDAC user guide</a> on our <a href=\"https://user.eumetsat.int/\" target=\"_blank\">User Portal</a>. Lets go ahead an create an example of a CLI search command using the variables in this script.\n",
    "\n",
    "*Note that we are providing the full path for the eumdac CLI exectuable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our CLI search command is\n",
      "------\n",
      "/opt/anaconda3/envs/cmts_ocean_case_studies/bin/eumdac search -c EO:EUM:DAT:0412 -s 2024-04-25T15:26:16 -e 2024-04-30T15:26:16 --geometry 'POLYGON((-23.25 20.75,-23.25 21.25,-22.75 21.25,-22.75 20.75,-23.25 20.75))' --timeliness NR\n"
     ]
    }
   ],
   "source": [
    "python_path = os.path.dirname(sys.executable)\n",
    "CLI_command_search = f\"{python_path}/eumdac search -c {collectionID} -s {dtstart.strftime(tformat)} -e {dtend.strftime(tformat)} --geometry '{polygon}' --timeliness {timeliness}\"\n",
    "print(f\"Our CLI search command is\\n------\\n{CLI_command_search}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this works by running this \"system command\" in Python using the `subprocess` library. We should get exactly the same answer as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3B_SL_2_WST____20240430T112844_20240430T113144_20240430T132402_0179_092_251_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240429T234146_20240429T234446_20240430T003119_0179_112_002_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240429T230550_20240429T230850_20240430T012853_0179_092_244_0360_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240429T115455_20240429T115755_20240429T135126_0179_092_237_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240428T232900_20240428T233200_20240429T001806_0179_092_230_0180_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240428T111903_20240428T112203_20240428T131506_0180_111_365_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T235511_20240427T235811_20240428T004452_0179_092_216_0180_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240427T114514_20240427T114814_20240427T134126_0179_111_351_2520_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T110917_20240427T111217_20240427T130127_0179_092_208_2700_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240427T110617_20240427T110917_20240427T130125_0179_092_208_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240426T231919_20240426T232219_20240427T000846_0179_111_344_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240426T113227_20240426T113527_20240426T132747_0179_092_194_2520_MAR_O_NR_003.SEN3\n",
      "S3A_SL_2_WST____20240425T234529_20240425T234829_20240426T003536_0179_111_330_0180_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240425T230932_20240425T231232_20240426T013226_0179_092_187_0360_MAR_O_NR_003.SEN3\n",
      "S3B_SL_2_WST____20240425T230632_20240425T230932_20240425T235545_0179_092_187_0180_MAR_O_NR_003.SEN3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = subprocess.Popen(CLI_command_search, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(process.communicate()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adapt this CLI search command to exploit the eumdac CLI download capability as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our CLI download command is\n",
      "------\n",
      "/opt/anaconda3/envs/cmts_ocean_case_studies/bin/eumdac download -y -c EO:EUM:DAT:0412 -s 2024-04-25T15:26:16 -e 2024-04-30T15:26:16 --geometry 'POLYGON((-23.25 20.75,-23.25 21.25,-22.75 21.25,-22.75 20.75,-23.25 20.75))' --timeliness NR -o /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads\n"
     ]
    }
   ],
   "source": [
    "CLI_command_download = f\"{python_path}/eumdac download -y -c {collectionID} -s {dtstart.strftime(tformat)} -e {dtend.strftime(tformat)} --geometry '{polygon}' --timeliness {timeliness} -o {os.getcwd()}\"\n",
    "print(f\"Our CLI download command is\\n------\\n{CLI_command_download}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that we have added the \"-y\" switch to force downloading without interaction, and the -o <OUTPUT_DIR> switch to specify our download directory*\n",
    "\n",
    "All we need to do now if place the command in the correct place and find a way to adapt the dates as required. How we approach this depends on our operating system..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "\n",
    "## On Linux and MacOSx: Using Cron\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux and Mac OSx contain an autoscheduler called \"cron\". You can access this and see what you are automating (which may be nothing!) by typing the following in a terminal;\n",
    "\n",
    "`crontab -l`\n",
    "\n",
    "to edit it, you can use\n",
    "\n",
    "`crontab -e`\n",
    "\n",
    "To use cron you need to add a line to the crontab and set the timing for scheduling the run. The timer is represented by five stars, which set minute, hour, day of the month, month and day of the week. You can find more information on timing in this <a href=\"https://crontab.guru/\" target=\"_blank\">web article</a>. To set our job to run at, for example, 09:00 every day (machine time) we would set the line in our crontab as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9 * * * /opt/anaconda3/envs/cmts_ocean_case_studies/bin/eumdac download -y -c EO:EUM:DAT:0412 -s 2024-04-25T15:26:16 -e 2024-04-30T15:26:16 --geometry 'POLYGON((-23.25 20.75,-23.25 21.25,-22.75 21.25,-22.75 20.75,-23.25 20.75))' --timeliness NR -o /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads\n"
     ]
    }
   ],
   "source": [
    "print(f\"0 9 * * * {CLI_command_download}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run `crontab -e` and copy and paste the line above into it before saving then this job is set to run on your system.\n",
    "\n",
    "**But there are two problems!**\n",
    "1. the dates are static and we need them to update\n",
    "2. there is no logging\n",
    "\n",
    "We can deal with the first point, by using the system commands from Linux and Mac OSx to update the data as we go. The date command we use depends on our operating system. We can deal with the second issue by adding a \">> <LOGFILE> 2>&1\" option at the end of our command. This will dump both standard output and errors to our log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For LINUX dates (GNU date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 'cron-ready' Linux CLI download command is\n",
      "------\n",
      "0 9 * * * /opt/anaconda3/envs/cmts_ocean_case_studies/bin/eumdac download -y -c EO:EUM:DAT:0412 -s $(date +\\%Y-\\%m-\\%d -d '5 day ago') -e $(date +\\%Y-\\%m-\\%d) --geometry 'POLYGON((-23.25 20.75,-23.25 21.25,-22.75 21.25,-22.75 20.75,-23.25 20.75))' --timeliness=NR -o /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads >> /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads/cronlog.log 2>&1\n"
     ]
    }
   ],
   "source": [
    "date_cmd_start = f\"$(date +\\%Y-\\%m-\\%d -d '{days_ago} day ago')\"\n",
    "date_cmd_end = \"$(date +\\%Y-\\%m-\\%d)\"\n",
    "CLI_command_download = f\"{python_path}/eumdac download -y -c {collectionID} -s {date_cmd_start} -e {date_cmd_end} --geometry '{polygon}' --timeliness={timeliness} -o {os.getcwd()} >> {os.path.join(os.getcwd(), 'cronlog.log')} 2>&1\"\n",
    "print(f\"Our 'cron-ready' Linux CLI download command is\\n------\\n0 9 * * * {CLI_command_download}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For OSX dates (BSD date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 'cron-ready' OSx CLI download command is\n",
      "------\n",
      "0 9 * * * /opt/anaconda3/envs/cmts_ocean_case_studies/bin/eumdac download -y -c EO:EUM:DAT:0412 -s $(date -v-5d +\\%Y-\\%m-\\%d) -e $(date +\\%Y-\\%m-\\%d) --geometry 'POLYGON((-23.25 20.75,-23.25 21.25,-22.75 21.25,-22.75 20.75,-23.25 20.75))' --timeliness=NR  -o /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads >> /Users/benloveday/Code/Git_Reps/CMTS/internal/applications/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads/cronlog.log\n"
     ]
    }
   ],
   "source": [
    "date_cmd_start = f\"$(date -v-{days_ago}d +\\%Y-\\%m-\\%d)\"\n",
    "date_cmd_end = \"$(date +\\%Y-\\%m-\\%d)\"\n",
    "CLI_command_download = f\"{python_path}/eumdac download -y -c {collectionID} -s {date_cmd_start} -e {date_cmd_end} --geometry '{polygon}' --timeliness={timeliness}  -o {os.getcwd()} >> {os.path.join(os.getcwd(), 'cronlog.log')}\"\n",
    "print(f\"Our 'cron-ready' OSx CLI download command is\\n------\\n0 9 * * * {CLI_command_download}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we have to add the back-slashes to escape how Linux and OSx interprets the percent signs*\n",
    "\n",
    "**We are almost done!** To use the above, you only need to make some small changes, as follows;\n",
    "1. make sure you have run this on your own system to get the correct path to eumdac\n",
    "1. replace the download directory with your directory of choice\n",
    "1. replace the logfile with your logfile of choice\n",
    "1. update the timing from 0 9 * * *, as required\n",
    "1. copy the updated code line into your crontab\n",
    "  \n",
    "Once you have done this, you should be all set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "\n",
    "## On Windows\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning: This approach is HIGHLY dependant on your system admin rights and if you are allowed to run scripts on your system**\n",
    "\n",
    "Windows schedules processes using a different method, called ScheduledTasks. We can set up the required task using a Powershell script (as Windows CMD mangles dates beyond belief). Before we go any further we need to set up our Powershell command as follows;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows Powershell dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cmd_start = f\"(Get-Date).AddDays(-{days_ago}).ToString('yyyy-MM-dd')\"\n",
    "date_cmd_end = \"(Get-Date).ToString('yyyy-MM-dd')\"\n",
    "CLI_command_download = f'{python_path}/eumdac download -y -c {collectionID} -s {date_cmd_start}\\n-e {date_cmd_end} --geometry \"{polygon}\" --timeliness {timeliness} -o {os.getcwd()}'\n",
    "print(CLI_command_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will require some adaptation of the paths to your **eumdac** executable and **output directory** on your system. Once we have this set up we need to write it to a powershell file called `eumdac_automate.ps1` on your system desktop. You can use notepad to create the file, but make sure you save it with the ps1 extension. Now you should follow these steps;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the scheduler by searching for \"Task Scheduler\" in your start menu.\n",
    "2. Once it is open, select \"Action > Create Basic task\", which will open the task creation wizard (left panel, below).\n",
    "3. Under the \"Name\" section, write EUMDAC_AUTOMATION (middle panel, below).\n",
    "4. Under the \"Trigger\" section, select Daily.\n",
    "5. Under the \"Daily\" section, select the time you want the script to run every day.\n",
    "6. Under the \"Action\" section, select \"Start a program\".\n",
    "7. Under the \"Start a Program\" section, write \"powershell\" in the Program/script section (right panel, below).\n",
    "8. Under the \"Start a Program\" section, you should add the following in the \"Add arguments section\": -File <YOUR_POWERSHELL_SCRIPT>, replacing the <YOUR_POWERSHELL_SCRIPT> tag with the full path the file we created and placed on your desktop.\n",
    "9. Click Next and Finish and you are done! Your automated downloader is in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/raw/main/img/TS_Panel1.png?ref_type=heads' align='left' width='33%'/>\n",
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/raw/main/img/TS_Panel2.png?ref_type=heads' align='left' width='33%'/>\n",
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/raw/main/img/TS_Panel3.png?ref_type=heads' align='left' width='33%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a bit more information you can see <a href=\"ttps://blog.netwrix.com/2018/07/03/how-to-automate-powershell-scripts-with-task-scheduler/\" target=\"_blank\">these instructions</a> on how to set up the automated tasks. Again, to reiterate, this approach will ONLY work if your system administrator allows you to run scripts through Powershell. If they do not, you should use the Pythonic approach used in [Section 4](#section4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>6. Conclusions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automating data acquisition is very often the first step in building an operational data processing chain. Using the tools and examples above you should be able to exploit either the `eumdac` Python library or CLI and either a Python, cron or ScheduledTasks based approach to begin building your own system. In all cases, when you are considering automation, it is important to act as a \"good citizen\". For example, try not to overload systems by sending very frequent download enquiries (e.g. every few seconds!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>7. Challenge (optional)\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have run the \"Within Python\" options in [Step 4](#section4), try to implement the appropriate workflows from [Step 5](#section5) for your system. If you need any help, please feel free to contact us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:.training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "content_type": "Software & code",
  "data_access": "Data Store",
  "deployment": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-case-studies/HEAD?labpath=Case_studies%2FAcq_syn%2FAutomated_downloads%2Automated_downloads.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/blob/main/Case_studies/Acq_syn/Automated_downloads/Automated_downloads.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "https://github.com/wekeo/ocean-case-studies/blob/main/Case_studies/Acq_syn/Automated_downloads/Automated_downloads.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/Acq_syn/Automated_downloads/Automated_downloads.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "description": "This Jupyter Notebook shows how to automate downloading level 2 SST products from the EUMETSAT Data Store",
  "image": "../../../img/thumbs/Automated_downloads_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "license": "MIT",
  "metadata_schema_version": "2.0.0",
  "originator": "EUMETSAT",
  "tags": {
   "data_provider": "EUMETSAT",
   "orbit": "LEO",
   "satellite": "Sentinel-3",
   "sensor": "SLSTR (Sentinel-3)",
   "service": "Sea surface temperature",
   "subtheme": "Ocean dynamics",
   "theme": "Marine",
   "variable": "Sea surface temperature"
  },
  "title": "Automating downloading of EUMETSAT Data Store level 2 SST products",
  "version": "2.0.0",
  "version_date": "2024-09-02"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
