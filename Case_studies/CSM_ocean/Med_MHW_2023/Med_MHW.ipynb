{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2024 European Union <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\"><img src=\"https://img.shields.io/badge/open-EUMETLAB-E67E22.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://user.eumetsat.int/data/themes/marine\"><img src=\"https://img.shields.io/badge/open-USER PORTAL-154360.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-case-studies/HEAD?labpath=Case_studies%2FCSM_ocean%2FMed_MHW_2023%2FMed_MHW.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/CSM_ocean/Med_MHW_2023/Med_MHW.ipynb\"><img src=\"https://img.shields.io/badge/launch-WEKEO-1a4696.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://code.insula.destine.eu/hub/\"><img src=\"https://img.shields.io/badge/launch-DestinE-f43fd3.svg\"></a></div></div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean case studies</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "This notebook has the following prerequisites:\n",
    "- **<a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">A Copernicus Marine Service (CMEMS) account</a>** to download data from the CMEMS Data Store\n",
    "\n",
    "There are no prerequisite notebooks for this module, but you may wish to look at the following notebooks on using level-2 SLSTR and level-4 OSTIA/C3S SST data; <br>\n",
    "\n",
    "- **<a href=\"../Atl_Med_anomalies/Atlantic_Med_SST_anomalies.ipynb\" target=\"_blank\">Sea surface temperature anomalies in the Northern Atlantic and Mediterranean Sea</a>**\n",
    "- **<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-SLSTR\" target=\"_blank\">Learn SLSTR (EUMETSAT Gitlab)</a>**\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine heatwaves in the Mediterranean Sea\n",
    "\n",
    "### <a id='dataused'>Data used\n",
    "\n",
    "| Dataset | EUMETSAT Data Store<br>collection ID | EUMETSAT collection<br>description | WEkEO dataset ID | WEkEO description | Copernicus Marine<br>Data Store product ID | Copernicus Marine<br>product description |\n",
    "|:--------------------:|:-----------------------:|:-------------:|:-----------------:|:-----------------:|:-----------------:|:-----------------:|\n",
    "| Global OSTIA SST (Reprocessed) | - | - | EO:MO:DAT:SST_GLO_SST_L4_REP_OBSERVATIONS_010_011 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_REP_OBSERVATIONS_010_011\" target=\"_blank\">Description</a> | SST_GLO_SST_L4_REP_OBSERVATIONS_010_011 | <a href=\"https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description\" target=\"_blank\">Description</a>|\n",
    "| ESA SST CCI and C3S reprocessed sea surface temperature analyses | - | - | EO:MO:DAT:SST_GLO_SST_L4_REP_OBSERVATIONS_010_024 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_REP_OBSERVATIONS_010_024\" target=\"_blank\">Description</a> | SST_GLO_SST_L4_REP_OBSERVATIONS_010_024 | <a href=\"https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_024/description\" target=\"_blank\">Description</a>|\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know;\n",
    "* where level-2 sea surface temperature (SST) data sets from EUMETSAT contributes to downstream Copernicus Marine Service products\n",
    "* how to download level-4 SST products from the Copernicus Marine Service using the **Copernicus Marine API** client\n",
    "* use time series of satellite SST data to investigate marine heatwaves using the `xmhw` package\n",
    "\n",
    "### Outline\n",
    "\n",
    "Concurrent with the past century's persistent warming of global oceans, marine heatwaves (periods of extreme regional ocean warming) have become more frequent and more extreme [[1]](#ref1). They occur in many areas around the world, from the Pacific Ocean to the Atlantic Ocean to the Mediterranean Sea [[2]](#ref2). Marine heatwaves can occur over thousands to millions of square kilometres, can persist for weeks to months, and can occur over significant depth. \n",
    "\n",
    "<figure><center>\n",
    "  <img src='https://tos.org/oceanography/assets/images/content/31-2_hobday_f2.jpg' width='75%'/>\n",
    "  <figcaption><a id='figure1'>Figure 1: Marine heat wave characterisations (Credit: <a href=\"https://www.researchgate.net/publication/325504331_Categorizing_and_Naming_Marine_Heatwaves\" target=\"_blank\">Hobday et al., 2018, CC-BY</a>)</figcaption>\n",
    "</center></figure>\n",
    "\n",
    "Marine heatwaves are generally defined as as period of abnormally high ocean temperatures, relative to a regional and seasonal average determined over time and can be categorised according to their severity ([Figure 1](#figure1)). Impacts of marine heatwaves include:\n",
    "* Impact on air-sea flux of CO2\n",
    "* Tropical cyclone formation\n",
    "* Coral bleaching [[3]](#ref3)\n",
    "* Mammal and sea bird mortality\n",
    "* Harmful Algal Blooms\n",
    "* Spatiotemporal shifts in habitats (affecting fisheries).\n",
    "\n",
    "A thorough review of biological impacts of marine heatwaves can be found in Smith et al. (2023) [[4]](#ref4).\n",
    "\n",
    "The exact statistical methodology used can vary, depending on the relation between the extreme heat and the impact of interest. In this notebook we will use a package called <a href=\"https://xmhw.readthedocs.io/en/latest/gettingstarted.html\" target=\"_blank\">**xmhw**</a>, an `xarray` based adaptation of the marine heatwave toolkit developed by Hobday et al. (2016) [[5]](#ref5), to identify marine heatwaves in the Mediterranean Sea. We are going to perform our analyses using two level-4 SST records, the global OSTIA reprocessed data set (SST foundation temperature, SST$_{fnd}$), and the combined the global ESA CCI and Copernicus Climate Change service (C3S) reprocessed data set (SST at 20 cm), which also uses the OSTIA processor. Both data sets are available through the Copernicus Marine Service and you can find more information on them in the [Data Used](#dataused) section, above. **Both** of these data sets ingest data level-2 SST data from the <a href=\"https://user.eumetsat.int/data/satellites/sentinel-3/sea-surface-temperature-service\" target=\"_blank\">Sea and Land Surface Temperature Radiometer</a> (SLSTR) aboard Copernicus Sentinel-3, operated by EUMETSAT, as well as level-2 SST data from the AVHRR sensor aboard <a href=\"https://user.eumetsat.int/data/satellites/metop/data\" target=\"_blank\">Metop</a> and sea ice information from the <a href=\"https://osi-saf.eumetsat.int/\" target=\"_blank\">EUMETSAT Ocean and Sea Ice Satellite Application Facility (OSI SAF)</a>.\n",
    "\n",
    "#### References\n",
    "\n",
    "1. <a id='ref1'></a><a href=\"https://www.science.org/doi/10.1126/science.aba0690\" target=\"_blank\">Laufkötter, C., Zscheischler, J., & Frölicher, T. L. (2020). High-impact marine heatwaves attributable to human-induced global warming. Science, 369(6511), 1621-1625.</a>\n",
    "2. <a id='ref2'></a><a href=\"https://egusphere.copernicus.org/preprints/2022/egusphere-2022-1119/\" target=\"_blank\">Guinaldo, T., Voldoire, A., Waldman, R., Saux Picart, S., & Roquet, H. (2023). Response of the sea surface temperature to heatwaves during the France 2022 meteorological summer. Ocean Science, 19(3), 629-647.</a>\n",
    "3. <a id='ref3'><a href=\"https://www.mdpi.com/2072-4292/12/23/3856\" target=\"_blank\">Skirving, W., Marsh, B., De La Cour, J., Liu, G., Harris, A., Maturi, E., ... & Eakin, C. M. (2020). CoralTemp and the coral reef watch coral bleaching heat stress product suite version 3.1. Remote Sensing, 12(23), 3856.</a>\n",
    "4. <a id='ref4'><a href=\"https://www.annualreviews.org/doi/full/10.1146/annurev-marine-032122-121437\" target=\"_blank\">Smith, K. E., Burrows, M. T., Hobday, A. J., King, N. G., Moore, P. J., Sen Gupta, A., ... & Smale, D. A. (2023). Biological impacts of marine heatwaves. Annual Review of Marine Science, 15, 119-145.</a>\n",
    "5. <a id='ref5'><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0079661116000057b\" target=\"_blank\">Hobday, A. J., Alexander, L. V., Perkins, S. E., Smale, D. A., Straub, S. C., Oliver, E. C., ... & Wernberg, T. (2016). A hierarchical approach to defining marine heatwaves. Progress in oceanography, 141, 227-238.</a>\n",
    "6. <a id='ref6'><a href=\"https://www.nature.com/articles/s41467-018-03732-9\" target=\"_blank\">Oliver, E. C., Donat, M. G., Burrows, M. T., Moore, P. J., Smale, D. A., Alexander, L. V., ... & Wernberg, T. (2018). Longer and more frequent marine heatwaves over the past century. Nature communications, 9(1), 1-12.</a>\n",
    "7. <a id='ref7'><a href=\"https://www.nature.com/articles/s43247-024-01239-4\" target=\"_blank\">Choi, H. Y., Park, M. S., Kim, H. S., & Lee, S. (2024). Marine heatwave events strengthen the intensity of tropical cyclones. Communications Earth & Environment, 5(1), 69.</a>\n",
    "8. <a id='ref8'><a href=\"https://www.nature.com/articles/s41598-020-63650-z\" target=\"_blank\">Cheung, W. W., & Frölicher, T. L. (2020). Marine heatwaves exacerbate climate change impacts for fisheries in the northeast Pacific. Scientific reports, 10(1), 6678.</a>\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOCTOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "\n",
    " 1. [Setting up our analysis](#section1)\n",
    " 1. [Viewing remote level-4 SST data from the Copernicus Marine Service](#section2)\n",
    " 1. [Downloading level-4 SST data from the Copernicus Marine Service](#section3)\n",
    " 1. [Loading and preparing the SST data sets](#section4)\n",
    " 1. [Comparing climatologies](#section5)\n",
    " 1. [Determining heatwave thresholds](#section6)\n",
    " 1. [Identifying heatwaves](#section7)\n",
    " 1. [Conclusions](#section8)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Setting up our analysis\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will set up all the parameters we need to run our notebook.\n",
    "\n",
    "We begin by importing all of the libraries that we need to run this notebook. If you have built your python using the environment file provided in this repository, then you should have everything you need. For more information on building environment, please see the repository **<a href=\"../../../../README.md\" target=\"_blank\">README</a>**. If you are running on WEkEO, you should ensure that you have selected the \"**miniwekeolab**\" environment/ipkernel using the menu option on the top right of the panel.\n",
    "\n",
    "The key library, `xmhw`, allows us to calculate marine heatwaves based on Hobday et al. (2016) [[5]](#ref5)</a>. For more information on this package, please see the **<a href=\"https://github.com/coecms/xmhw\" target=\"_blank\">xmhw</a>** GitHub pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e8fe95d5-2506-4236-8126-4d62fac94b41\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"e8fe95d5-2506-4236-8126-4d62fac94b41\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"e8fe95d5-2506-4236-8126-4d62fac94b41\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"e8fe95d5-2506-4236-8126-4d62fac94b41\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e8fe95d5-2506-4236-8126-4d62fac94b41\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bk             # a library that supports interactive plotting\n",
    "import bokeh.models as bm               # a library that supports interactive plotting models\n",
    "import bokeh.io as bi                   # a library that supports interactive plotting display options\n",
    "import copernicusmarine                 # a library to help us access CMEMS data\n",
    "import getpass                          # a library to help us enter passwords\n",
    "import numpy as np                      # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "import os                               # a library that allows us access to basic operating system commands\n",
    "from pathlib import Path                # a library that helps construct system path objects\n",
    "from scipy import stats                 # a library that supports statistical analysis\n",
    "import warnings                         # a library the helps us to manage warnings\n",
    "import xarray as xr                     # a powerful library that helps us work efficiently with multi-dimensional arrays\n",
    "from xcube.webapi.viewer import Viewer  # a library that provides the Xcube viewer\n",
    "from xmhw.xmhw import detect, threshold # a library that support Xarray calculation of marine heatwaves, based on Hobday et al. 2016 <<<\n",
    "\n",
    "# turn off warnings and initialise bokeh\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "bk.output_notebook()\n",
    "\n",
    "# set Xcube server if running on WEkEO\n",
    "if \"WEKEO_DATABROKER_URL\" in os.environ:\n",
    "    os.environ[\"XCUBE_JUPYTER_LAB_URL\"] = f\"https://jupyterhub.prod.wekeo2.eu/user/{os.environ['JUPYTERHUB_USER']}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have access to all the libraries that we need to run our analysis. Nothing else will be imported during this notebook.\n",
    "\n",
    "We are going to study an area of the western Mediterannean Sea around Sardinia and Corsica over a 30 year period. Below we will define the spatial extent of our region of interest `ROI` and the time period we are interested in. We will define the latter by specifying the `final_year` of the analysis and the number of years (`n_years`) to consider. The approach here uses a **shifting baseline**, but you can adapt it to use a **fixed baseline** by selecting your start year explicitly to build your climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our bounding box (W, E, S, N)\n",
    "ROI = [3.0, 8.5, 41.0, 44.5]\n",
    "\n",
    "# defining our temporal bounds\n",
    "final_year = 2021\n",
    "n_years = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now specify the Copernicus Marine Service (CMEMS) data sets that we are interested in. We are interested in two data sets, as described above. We are going to store all the information associated with these data sets in a `dictionary` that has two primary keys or `tags`, *OSTIA* and *CCI_C3S*.\n",
    "\n",
    "This dictionary will hold the information on the `sources` for each data, which point to the unique ID of the data set in the CMEMS Data Stoire. It will also hold information on the file name (`savefile`) that we will write the data to when we download it. Finally, we will specify the `variables` we want to retrieve.\n",
    "\n",
    "*Note: we are downloading data from two `sources` in the *CCI_C3S* case. The data in the two sources is comparable, but spans different times period, and so we will concatenate these into a single time series before we perform our analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tags to identify datasets\n",
    "tags = [\"OSTIA\", \"CCI_C3S\"]\n",
    "\n",
    "# create dictionary\n",
    "datasets = {}\n",
    "for tag in tags:\n",
    "    datasets[tag] = {}\n",
    "\n",
    "# store information on our data requirements in the dictionary\n",
    "datasets[\"OSTIA\"][\"sources\"] = \"METOFFICE-GLO-SST-L4-REP-OBS-SST\"\n",
    "datasets[\"OSTIA\"][\"savefile\"] = \"SST_OSTIA.nc\"\n",
    "\n",
    "datasets[\"CCI_C3S\"][\"sources\"] = [\"ESACCI-GLO-SST-L4-REP-OBS-SST\", \"C3S-GLO-SST-L4-REP-OBS-SST\"]\n",
    "datasets[\"CCI_C3S\"][\"savefile\"] = \"SST_CCI_C3S.nc\"\n",
    "\n",
    "# set the variable we wish to retrieve\n",
    "variables = [\"analysed_sst\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let us set a switch (`download_data`) that determines if we should download new data or use what we already have. If you are running this script for the first time this should eb set to True, but you can set it to False for future iterations if you want to adapt and run the script again with existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='section99'></a>Defining functions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a quick function to plot marine heatwave occurences\n",
    "\n",
    "Before we move on to our analysis, we are going to define a quick function for use later on. We define functions when we have some code that we want to use repeatedly later on. In this case, the function, `plot_MHW_zone`, will be called in section 7 and used to highlight areas that show marine heatwaves. You don't need to worry about how this function works, and so it is hidden by default. You can click on the \"+1 cell hidden\" box below if you want to see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MWH_zone(axis, t1, t2, times, scaling, norm_scaling):\n",
    "    \"\"\"Function to highlight marine heatwave periods.\n",
    "    \n",
    "    Args:\n",
    "        axis: the axis to plot into\n",
    "        t1,t2: the start and end time of the marine heat wave period\n",
    "        times: the time variable\n",
    "        normalised_intensity: the intensity of the heatwave (0-1; used to scale the colour)\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    start_date = times.time[int(t1)].dt.date.values\n",
    "    end_date = times.time[int(t2 + 1)].dt.date.values\n",
    "    length = int(t2) - int(t1) + 1\n",
    "    index = int(t_values.tolist().index(t1) / 2 + 1)\n",
    "    \n",
    "    # Prepare the data to plot\n",
    "    data_MHW = bm.ColumnDataSource(data=dict(\n",
    "            x=np.array(times.time[int(t1) : int(t2 + 1)]),\n",
    "            y1=np.array(times[int(t1) : int(t2 + 1)]),\n",
    "            y2=np.full(length, 10)))\n",
    "\n",
    "    fill_color = '#%02x%02x%02x' % (int(norm_scaling* 255), 1, 1)\n",
    "    \n",
    "    # Fill the required area\n",
    "    v_area = p_MHW.varea(\"x\", \"y1\", \"y2\", source=data_MHW, fill_color=fill_color,\n",
    "                         hover_alpha=0.9, alpha=0.6)\n",
    "\n",
    "    # Add a hovertool to the zone\n",
    "    p_MHW.add_tools(bm.HoverTool(renderers=[v_area], tooltips=[\n",
    "                (\"Index\", f\"{index}\"), (\"Dates\", f\"{start_date} - {end_date}\"),\n",
    "                (\"Duration\", f\"{length} days\"),\n",
    "                (\"Category/Intensity\", f\"{float(scaling)}\")],\n",
    "            formatters={\"@start\": \"datetime\", \"@end\": \"datetime\"}, toggleable=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Viewing remote level-4 SST data from the Copernicus Marine Service\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our analysis, we will access data from the Copernicus Marine Service using the Copernicus Marine API. In this section, we will load the data directly into memory, without the need to download it to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing Copernicus Marine Service products\n",
    "\n",
    "To retrieve the data, we need will use the <a href=\"https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction\" target=\"_blank\">Copernicus Marine API</a>. This allows us to remotely subset the data and read it directly into memory, for immediate use. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install the toolkit using;\n",
    "\n",
    "`conda install -c conda-forge copernicusmarine`\n",
    "\n",
    "To download data using the Copernicus Marine API, you need to provide credentials. To obtain these, you should register at the <a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">Copernicus Marine Service</a> for an account and take note of you `username` and `password`. If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: For more information on authentication options please see this <a href=\"https://help.marine.copernicus.eu/en/articles/8185007-copernicus-marine-toolbox-credentials-configuration\" target=\"_blank\">web article</a>.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default location expected by the copernicusmarine package\n",
    "copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')\n",
    "\n",
    "# Create it only if it does not already exists\n",
    "if not copernicus_marine_credentials_file.is_file():\n",
    "    copernicusmarine.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have authenticated the `copernicusmarine` API, we can go ahead and launch our first data retrieval using the `open_dataset` method. You can see in cell below we use the information we set in [Section1](#section1) to specify the data set, variable and spatio-temporal coverage of our request. The result will be stored in an `xarray` Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = copernicusmarine.open_dataset(\n",
    "    dataset_id=datasets[\"OSTIA\"][\"sources\"],\n",
    "    variables=variables,\n",
    "    minimum_longitude=ROI[0],\n",
    "    maximum_longitude=ROI[1],\n",
    "    minimum_latitude=ROI[2],\n",
    "    maximum_latitude=ROI[3],\n",
    "    start_datetime= f\"{final_year - n_years}-01-01\",\n",
    "    end_datetime= f\"{final_year}-12-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at our result..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the above that we have downloaded a \"cube\" of data. You can see this in the `analysed_sst` variable, which has dimensions of time, latitude, longitude. There are a variety of nice plotting tools to view gridded data, and we are going to use one called `xcube` that allows us to explore temporally and spatially. \n",
    "\n",
    "Below, we will set up our \"viewer\", configuring a *style* that will determine how we see the data in the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m viewer \u001b[38;5;241m=\u001b[39m \u001b[43mViewer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStyles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColorMappings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manalysed_sst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mValueRange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m285\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m290\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColorBar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpectral_r\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/viewer/viewer.py:96\u001b[0m, in \u001b[0;36mViewer.__init__\u001b[0;34m(self, server_config, roots, max_depth)\u001b[0m\n\u001b[1;32m     93\u001b[0m thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     94\u001b[0m thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server \u001b[38;5;241m=\u001b[39m \u001b[43mServer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTornadoFramework\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_io_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39madd_callback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server\u001b[38;5;241m.\u001b[39mstart)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/server/server.py:84\u001b[0m, in \u001b[0;36mServer.__init__\u001b[0;34m(self, framework, config, extension_registry)\u001b[0m\n\u001b[1;32m     82\u001b[0m assert_instance(framework, Framework)\n\u001b[1;32m     83\u001b[0m assert_instance(config, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping)\n\u001b[0;32m---> 84\u001b[0m apis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_apis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_registry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension_registry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m api \u001b[38;5;129;01min\u001b[39;00m apis:\n\u001b[1;32m     86\u001b[0m     LOG\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded service API \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/server/server.py:210\u001b[0m, in \u001b[0;36mServer.load_apis\u001b[0;34m(cls, config, extension_registry)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Collect effective APIs\u001b[39;00m\n\u001b[1;32m    209\u001b[0m api_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(incl_api_names)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(excl_api_names))\n\u001b[0;32m--> 210\u001b[0m apis: \u001b[38;5;28mlist\u001b[39m[Api] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    211\u001b[0m     ext\u001b[38;5;241m.\u001b[39mcomponent \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m api_extensions \u001b[38;5;28;01mif\u001b[39;00m ext\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m api_names\n\u001b[1;32m    212\u001b[0m ]\n\u001b[1;32m    214\u001b[0m api_lookup \u001b[38;5;241m=\u001b[39m {api\u001b[38;5;241m.\u001b[39mname: api \u001b[38;5;28;01mfor\u001b[39;00m api \u001b[38;5;129;01min\u001b[39;00m apis}\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_required_apis_available\u001b[39m():\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# Assert that required APIs are available.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/server/server.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Collect effective APIs\u001b[39;00m\n\u001b[1;32m    209\u001b[0m api_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(incl_api_names)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(excl_api_names))\n\u001b[1;32m    210\u001b[0m apis: \u001b[38;5;28mlist\u001b[39m[Api] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m api_extensions \u001b[38;5;28;01mif\u001b[39;00m ext\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m api_names\n\u001b[1;32m    212\u001b[0m ]\n\u001b[1;32m    214\u001b[0m api_lookup \u001b[38;5;241m=\u001b[39m {api\u001b[38;5;241m.\u001b[39mname: api \u001b[38;5;28;01mfor\u001b[39;00m api \u001b[38;5;129;01min\u001b[39;00m apis}\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_required_apis_available\u001b[39m():\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# Assert that required APIs are available.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/util/extension.py:72\u001b[0m, in \u001b[0;36mExtension.component\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extension component.\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/util/extension.py:322\u001b[0m, in \u001b[0;36mimport_component.<locals>._load\u001b[0;34m(extension)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(extension: Extension):\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m spec\n\u001b[0;32m--> 322\u001b[0m     component \u001b[38;5;241m=\u001b[39m \u001b[43m_import_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_component\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m         component \u001b[38;5;241m=\u001b[39m transform(component, extension)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/util/extension.py:356\u001b[0m, in \u001b[0;36m_import_component\u001b[0;34m(component_spec, force_component)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m component_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124millegal spec, missing component name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 356\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, component_name) \u001b[38;5;28;01mif\u001b[39;00m component_name \u001b[38;5;28;01melse\u001b[39;00m module\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2018-2024 by xcube team and contributors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Permissions are hereby granted under the terms of the MIT License:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# https://opensource.org/licenses/MIT.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroutes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/routes.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxcube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApiError\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxcube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApiHandler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputeContext\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrollers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compute_operations\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/api.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxcube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Api\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CONFIG_SCHEMA\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputeContext\n\u001b[1;32m      9\u001b[0m api \u001b[38;5;241m=\u001b[39m Api(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxcube Datasets Compute API\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     create_ctx\u001b[38;5;241m=\u001b[39mComputeContext,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/context.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OP_REGISTRY\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Register default operations:\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxcube.webapi.compute.operations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m LocalExecutor \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# TODO: we should create a module 'job' and define better job classes.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#   Here we use dicts for time being.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/operations.py:22\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxcube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operation\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxcube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_param\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129;43m@operation\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129;43m@op_param\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBounding box\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBounding box using the dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms CRS coordinates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The rest of the schema is inferred from the function signature.\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mspatial_subset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Create a spatial subset from given dataset.\"\"\"\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/op/decorator.py:81\u001b[0m, in \u001b[0;36mop_param.<locals>.decorator\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(op: Callable):\n\u001b[1;32m     80\u001b[0m     _assert_decorator_target_ok(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop_param\u001b[39m\u001b[38;5;124m\"\u001b[39m, op)\n\u001b[0;32m---> 81\u001b[0m     op_info \u001b[38;5;241m=\u001b[39m \u001b[43mop_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     op_param_schema \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/op/registry.py:27\u001b[0m, in \u001b[0;36mOpRegistry.register_op\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m     25\u001b[0m prev_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mget(op_name)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m prev_op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function:\n\u001b[0;32m---> 27\u001b[0m     op_info \u001b[38;5;241m=\u001b[39m \u001b[43mOpInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_op_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     op \u001b[38;5;241m=\u001b[39m op_info\u001b[38;5;241m.\u001b[39mmake_op(function)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops[op_name] \u001b[38;5;241m=\u001b[39m op\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/site-packages/xcube/webapi/compute/op/info.py:114\u001b[0m, in \u001b[0;36mOpInfo.new_op_info\u001b[0;34m(cls, op)\u001b[0m\n\u001b[1;32m    112\u001b[0m     param_py_types[param_name] \u001b[38;5;241m=\u001b[39m py_type\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(py_type):\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpy_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMultiLevelDataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m# extract function from get_effective_parameters\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         param_schema \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    119\u001b[0m         }\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cmts_sea_surface_temperature_applications/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "viewer = Viewer(\n",
    "    server_config={\n",
    "        \"Styles\": [\n",
    "            {\n",
    "                \"Identifier\": \"SST\",\n",
    "                \"ColorMappings\": {\n",
    "                    \"analysed_sst\": {\"ValueRange\": [285, 290], \"ColorBar\": \"Spectral_r\"}\n",
    "                },\n",
    "            }        \n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now add our Dataset to the viewer, associating it with our defined *style*, and show the viewer. The viewer will open the latest \"time slice\" of the data set, but you can iterate it in time using the arrow buttons and click on any \"populated\" pixel to see a time series.\n",
    "\n",
    "Explore the tool to see how the SST field changes in time.\n",
    "\n",
    "*Hint: you may need to rerun the cell above with different temperature bounds when you reach summer! The current ones are chosen for winter, and are in degrees Kelvin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_dataset(ds, title=\"OSTIA\", style=\"SST\");\n",
    "viewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OSTIA data sets we are working with is 0.05$^{o}$ (~5 km at this latitude), so we can see some detail on the mesoscale variability in the region - though in practice the effects of the interpolation scheme reduce the effective resolution. If you have clicked on the SST field to create a time series, you will also most likely see a strong seasonal cycle and possibly some hints of a warming trend, which very much matches the temperature anomalies across the region in the last few years! If you are interested, here is another notebook (<a href=\"../Atl_Med_anomalies/Atlantic_Med_SST_anomalies.ipynb\" target=\"_blank\">Sea surface temperature anomalies in the Northern Atlantic and Mediterranean Sea</a>) that explores this in more detail.\n",
    "\n",
    "Lets now move on to some times series analysis with a view to identifying marine heat waves in this region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Downloading level-4 SST data from the Copernicus Marine Service\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we connected the the Copernicus Marine Service Data Store in a way that allowed us to work directly with the data. However, as we want to perform some more in depth analysis we are now going to download the data and write it to a file. We can do this using the `open_dataset` method to connect to the data, then take the mean of the resulting array in both spatial dimensions to create a time series, thatt we will then write it to our pre-specified file name.\n",
    "\n",
    "Lets do this for OSTIA...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    \n",
    "    ds = copernicusmarine.open_dataset(\n",
    "        dataset_id=datasets[\"OSTIA\"][\"sources\"],\n",
    "        variables=variables,\n",
    "        minimum_longitude=ROI[0],\n",
    "        maximum_longitude=ROI[1],\n",
    "        minimum_latitude=ROI[2],\n",
    "        maximum_latitude=ROI[3],\n",
    "        start_datetime= f\"{final_year - n_years}-01-01\",\n",
    "        end_datetime= f\"{final_year}-12-31\")\n",
    "\n",
    "    # create times series\n",
    "    ts = ds.analysed_sst.mean(dim=[\"latitude\", \"longitude\"])\n",
    "    \n",
    "    # Store the time series ts locally.\n",
    "    ts.to_netcdf(datasets[\"OSTIA\"][\"savefile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets do this for the CCI and C3S data sets, this time concatenating them into one times series. We can ONLY do this as the data sets are compatible and exactly follow on from each other with no temporal overlap or gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "\n",
    "    sources = []\n",
    "    for source in datasets[\"CCI_C3S\"][\"sources\"]:\n",
    "        sources.append(copernicusmarine.open_dataset(\n",
    "            dataset_id=source,\n",
    "            variables=variables,\n",
    "            minimum_longitude=ROI[0],\n",
    "            maximum_longitude=ROI[1],\n",
    "            minimum_latitude=ROI[2],\n",
    "            maximum_latitude=ROI[3],\n",
    "            start_datetime= f\"{final_year - n_years}-01-01\",\n",
    "            end_datetime= f\"{final_year}-12-31\").analysed_sst.mean(dim=[\"latitude\", \"longitude\"]))\n",
    "\n",
    "    # create times series\n",
    "    ts = xr.concat(sources, dim=\"time\")\n",
    "\n",
    "    # Store the time series ts locally.\n",
    "    ts.to_netcdf(datasets[\"CCI_C3S\"][\"savefile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now notice that, in the sidebar on the left, you have two netCDF files ready for analysis; SST_OSTIA.nc and SST_CCI_C3S.nc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>4. Loading and preparing the SST data sets\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded and created our time series, but we need to read it in to work with the data. The cell below will load our time-series in and store it in a dictionary called `heatwaves`. It will also change the SST from degrees K to degrees C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatwaves = {}\n",
    "\n",
    "K_to_C = - 273.15\n",
    "for tag in tags:\n",
    "    heatwaves[tag] = {}\n",
    "    ts = xr.open_dataarray(f\"SST_{tag}.nc\")\n",
    "    ts = ts + K_to_C\n",
    "    heatwaves[tag][\"time_series\"] = ts\n",
    "    ts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data ready to use, its time to analyse it for the presence of heatwaves. This is where we apply the `xmhw` tool. We are going to iterate through our two data sets (OSITA and CCI_C3S) and calculate the following quantities:\n",
    "\n",
    "The following help us with plotting:\n",
    "\n",
    "* **max_year**: the final year of the time series as a numpy array\n",
    "* **min_year**: the first year of the time series as a numpy array\n",
    "* **time**: the time variable stored in our dictionary as a numpy array\n",
    "* **SST**: the SST signal in our dictionary as a numpy array\n",
    "\n",
    "The following help us determine climate thresholds:\n",
    "\n",
    "*  **xmhw**_thresholds: the results of the xmhw <a href=\"https://xmhw.readthedocs.io/en/latest/threshold.html\" target=\"_blank\">`thresholds` method</a>, which gives us both the mean climatology (*seas*) and 90% threshold values (*thresh*)\n",
    "*  **doy**: the day of year as a numpy array\n",
    "*  **xmhw_seas_clim**: the annual climatology (*seas*) as a numpy array\n",
    "*  **xmhw_thresh_clim**: the annual 90% threshold (*thresh*) as a numpy array\n",
    "*  **xmhw_seas**: the climatology copied across the whole time series as a numpy array\n",
    "*  **xmhw_thresh**: the 90% threshold copied across the whole time series as a numpy array\n",
    "\n",
    "The following calculates the presence of heatwaves:\n",
    "\n",
    "*  **mhws**: the results of the xmhw <a href=\"https://xmhw.readthedocs.io/en/latest/detect.html\" target=\"_blank\">`detect` method</a>, which determines the presence of our heatwaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in tags:\n",
    "    heatwaves[tag][\"max_year\"] = np.array(heatwaves[tag][\"time_series\"][-1].time.dt.year)\n",
    "    heatwaves[tag][\"min_year\"] = np.array(heatwaves[tag][\"time_series\"][0].time.dt.year)\n",
    "    heatwaves[tag][\"time\"] = np.array(heatwaves[tag][\"time_series\"].time) \n",
    "    heatwaves[tag][\"SST\"] = np.array(heatwaves[tag][\"time_series\"]) \n",
    "\n",
    "    # heatwave threshold calculations\n",
    "    heatwaves[tag][\"xmhw_thresholds\"] = threshold(heatwaves[tag][\"time_series\"])\n",
    "    heatwaves[tag][\"doy\"] = np.array(heatwaves[tag][\"xmhw_thresholds\"].doy)\n",
    "    heatwaves[tag][\"xmhw_seas_clim\"] = np.array(heatwaves[tag][\"xmhw_thresholds\"].seas)\n",
    "    heatwaves[tag][\"xmhw_thresh_clim\"] = np.array(heatwaves[tag][\"xmhw_thresholds\"].thresh)\n",
    "    heatwaves[tag][\"xmhw_seas\"] = heatwaves[tag][\"xmhw_seas_clim\"][heatwaves[tag][\"time_series\"].time.dt.dayofyear - 1]\n",
    "    heatwaves[tag][\"xmhw_thresh\"] = heatwaves[tag][\"xmhw_thresh_clim\"][heatwaves[tag][\"time_series\"].time.dt.dayofyear - 1]\n",
    "\n",
    "    # heatwave detection calculations\n",
    "    heatwaves[tag][\"mhws\"] = detect(heatwaves[tag][\"time_series\"], heatwaves[tag][\"xmhw_thresholds\"].thresh, heatwaves[tag][\"xmhw_thresholds\"].seas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis is now complete and we are ready to explore the results, which we will do interactively using a plotting packages called `bokeh`. The cell below takes the **climatology** variables from our dictionary and gets them ready for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clim = bm.ColumnDataSource(\n",
    "    data=dict(\n",
    "        doy_OSTIA=heatwaves[tags[0]][\"doy\"],\n",
    "        seas_clim_OSTIA=heatwaves[tags[0]][\"xmhw_seas_clim\"],\n",
    "        thresh_clim_OSTIA=heatwaves[tags[0]][\"xmhw_thresh_clim\"],\n",
    "        doy_CCI_C3S=heatwaves[tags[1]][\"doy\"],\n",
    "        seas_clim_CCI_C3S=heatwaves[tags[1]][\"xmhw_seas_clim\"],\n",
    "        thresh_clim_CCI_C3S=heatwaves[tags[1]][\"xmhw_thresh_clim\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this cell gets the **full times series** variables from our dictionary and gets them ready for plotting... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bm.ColumnDataSource(\n",
    "    data=dict(\n",
    "        t_OSTIA=heatwaves[tags[0]][\"time\"],\n",
    "        sst_OSTIA=heatwaves[tags[0]][\"SST\"],\n",
    "        seas_OSTIA=heatwaves[tags[0]][\"xmhw_seas\"],\n",
    "        thresh_OSTIA=heatwaves[tags[0]][\"xmhw_thresh\"],\n",
    "        t_CCI_C3S=heatwaves[tags[1]][\"time\"],\n",
    "        sst_CCI_C3S=heatwaves[tags[1]][\"SST\"],\n",
    "        seas_CCI_C3S=heatwaves[tags[1]][\"xmhw_seas\"],\n",
    "        thresh_CCI_C3S=heatwaves[tags[1]][\"xmhw_thresh\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, everything is ready, lets start exploring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>5. Comparing climatologies\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ability to determine the presence of a heatwaves depends intimately on the climatology we use as a baseline. Here, we are working with two contemporaneous data sets, allowing us to compare their mean seasonal climatologies. The cell below will plot both climatologies.\n",
    "\n",
    "The plot will be interactive, allowing you to explore the data more fully. We will also set up some tools to help with this exploration; you are free to use the widgets on the right hand side of the plot to zoom, pan, reset and export the plot, and you should also see the time series values highlighted as you run your mouse over the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our figure\n",
    "p = bk.figure(height=600, width=1000,\n",
    "    title=f\"SST Climatology [climatology: {tag}, {heatwaves[tags[0]]['min_year']} - {heatwaves[tags[0]]['max_year']}]\",\n",
    "    x_axis_label=\"Day of year\", y_axis_label=r\"\\[ SST \\, [^\\circ C] \\]\")\n",
    "\n",
    "# Plot the climatology and collect the plot, hover and legend entries\n",
    "plots = [] ; hovers = [] ; entries = []\n",
    "count = -1\n",
    "for tag, cols, loc in zip(tags, [\"blue\", \"black\"], [\"left\", \"right\"]):\n",
    "    count = count + 1\n",
    "    plots.append(p.line(x=f\"doy_{tag}\", y=f\"seas_clim_{tag}\", source=data_clim, line_width=1.5, color=cols))\n",
    "    hovers.append(bm.HoverTool(renderers=[plots[count]], tooltips=[(\"Day of year\", f\"@doy_{tag}\"), (f\"SST [{tag}]\", f\"@seas_clim_{tag}\")],\n",
    "        mode=\"vline\", attachment=loc))\n",
    "    entries.append((f\"Seasonal climatology [{tag}]\", [plots[count]]))\n",
    "\n",
    "# Add the hover tools\n",
    "p.add_tools(hovers[0], hovers[1])\n",
    "\n",
    "# Add the legend & show the plot\n",
    "legend = bm.Legend(items=[entries[0], entries[1]], location=\"top_left\")\n",
    "p.add_layout(legend, \"center\")\n",
    "bi.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the difference are subtle, we can see that there are some anomalies between the two data sets, even though they;\n",
    "\n",
    "* are generated by the same processing system (OSTIA),\n",
    "* cover identical areas,\n",
    "* cover identical time periods, and\n",
    "* have the same resolution.\n",
    "\n",
    "However, this is not so surprising, as, they **DO NOT** show the same variable. While OSTIA contains the foundation temperature (<a href=\"https://www.ghrsst.org/wp-content/uploads/2021/04/newerSSTdef.gif\" target=\"blank\">SST$_{fnd}$</a>), which contains no diurnal cycle (typically ~10 m), the CCI/C3S dataset is SST at 20 cm as it is designed to be compared with the historical data from drifting buoys and contains some of the diurnal cycle (nominally at 10:30 ad 22:30). Also, while both data sets are \"reprocessed\" there is differences in the criteria used to select the input data. We have some justification to expect that the CCI_C3S record is of slightly higher quality, as it has more of a climate focus. By default, we will select this data set for the rest of our work, but you should feel free to switch to the OSTIA data if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>6. Determining heatwave thresholds\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have investigated our climatology. Lets now see check our \"threshold\" level - the level which must be exceeded for us to start to consider an event a heatwave. We'll begin by selecting our data set, as discussed above. This is simply done, using the tags we have set up in our dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"CCI_C3S\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make another interactive plot, but this time plot our seasonal climatology and its associated threshold. The plot will have the same controls as the previous example, and  so you will find the code is very similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bk.figure(height=600, width=1000,\n",
    "    title=f\"SST Climatology and MHW detection threshold [climatology: {tag}, {heatwaves[tag]['min_year']} - {heatwaves[tag]['max_year']}]\",\n",
    "    x_axis_label=\"Day of year\", y_axis_label=r\"\\[ SST \\, [^\\circ C] \\]\")\n",
    "\n",
    "# Plot the climatology and detection threshold\n",
    "plots = []; hovers = []; entries = []\n",
    "\n",
    "count = -1\n",
    "for var, cols, loc, label, style in zip([\"seas_clim\", \"thresh_clim\"], [\"black\", \"blue\"], [\"left\", \"right\"],\n",
    "                                        [f\"Seasonal climatology [{tag}]\", \"MHW Threshold (90%)\"], [\"solid\", \"dashed\"]):\n",
    "    count = count + 1\n",
    "    plots.append(p.line(x=f\"doy_{tag}\", y=f\"{var}_{tag}\", source=data_clim, line_width=1.5, color=cols, line_dash=style))\n",
    "    hovers.append(bm.HoverTool(renderers=[plots[count]], tooltips=[(\"Day of year\", f\"@doy_{tag}\"), (label, f\"@{var}_{tag}\")],\n",
    "        mode=\"vline\", attachment=loc))\n",
    "    entries.append((label, [plots[count]]))\n",
    "\n",
    "line_dash=\"dashed\"\n",
    "\n",
    "# Add the hover tools\n",
    "p.add_tools(hovers[0], hovers[1])\n",
    "\n",
    "# Add the legend & plot\n",
    "legend = bm.Legend(items=[entries[0], entries[1]], location=\"top_left\")\n",
    "p.add_layout(legend, \"center\")\n",
    "bi.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is not particularly surprising, but it is important to note that as a result of increased variability, the 90% threshold is further from the seasonal climatology in the summer period than it is at the rest of the year.\n",
    "\n",
    "Lets now see how the seasonal climatology and threshold value compare with the entire time series....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bk.figure(height=600, width=1000,\n",
    "    title=f\"SST Climatology and MHW detection threshold [climatology: {tag}, {heatwaves[tag]['min_year']} - {heatwaves[tag]['max_year']}]\",\n",
    "    x_axis_type=\"datetime\", x_axis_label=\"Date\",\n",
    "    y_axis_label=r\"\\[ SST \\, [^\\circ C] \\]\", y_range = (13.5,32))\n",
    "\n",
    "# Plot the climatology and detection threshold\n",
    "p_sst = p.line(f\"t_{tag}\", f\"sst_{tag}\", source=data, line_width=1.5, color=\"red\")\n",
    "p_thresh = p.line(f\"t_{tag}\", f\"thresh_{tag}\", source=data, line_width=1.5, color=\"blue\", line_dash=\"dashed\")\n",
    "p_seas = p.line(f\"t_{tag}\", f\"seas_{tag}\", source=data, line_width=1.5, color=\"black\")\n",
    "\n",
    "# Add a hovertool to the plot\n",
    "p.add_tools(bm.HoverTool(renderers=[p_thresh], tooltips=[\n",
    "            (\"Date\", f\"@t_{tag}\"+\"{%F}\"),\n",
    "            (\"Threshold\", f\"@thresh_{tag}\"),\n",
    "            (\"SST\", f\"@sst_{tag}\"),\n",
    "            (\"Climatology\", f\"@seas_{tag}\"),\n",
    "        ], mode=\"vline\", formatters={f\"@t_{tag}\": \"datetime\"}))\n",
    "\n",
    "# Add the legend & plot\n",
    "legend = bm.Legend(items=[(f\"SST [{tag}]\", [p_sst]), (f\"Seasonal climatology [{tag}]\", [p_seas]),\n",
    "        (f\"90% MHW detection threshold\", [p_thresh])], location=\"top_left\", ncols = 1)\n",
    "\n",
    "# we will use the same axis in the next plot, so keep it for later\n",
    "p_MHW = p\n",
    "p.add_layout(legend, \"center\")\n",
    "bi.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 3rd icon down in the toolbox, you can draw a box to zoom in on any part of the plot you like (reset with the two arrows in a circle). There are clear periods here where we can see that the SST (in red) crosses the threshold. In fact, it appears to have done so every summer since 2017, with a suggestion of a general increase in SST over our 20 year time period.\n",
    "\n",
    "Lets now move on to our final section, where we investigate if these periods of warm SST signals represent heatwaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>7. Identifying heatwaves\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final plot, we are going to explicitly label the marine heatwave events, shading them in red.\n",
    "\n",
    "In [Section4](#section4), we called our `detect` method, which performed all of our calculations related to identifying marine heat waves. This method will give us not only the presence and duration of event (with some flexibility), but provides quite a lot of different output parameters, including category, and intensity. Lets first look at the events we have found, and tabulate some of their parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index\\tStart\\t\\tCategory\\tDuration (days)\\tMax. intensity [C]\\n\")\n",
    "index = 0\n",
    "for start_date, category, duration,intensity in zip(heatwaves[tag][\"mhws\"].time_start.dt.date.values,\n",
    "                                                    heatwaves[tag][\"mhws\"].category.values,\n",
    "                                                    heatwaves[tag][\"mhws\"].duration.values,\n",
    "                                                    heatwaves[tag][\"mhws\"].intensity_max.values):\n",
    "    index = index + 1\n",
    "    print(f'{index}\\t{start_date}\\t{category}\\t\\t{duration}\\t\\t{\"%.2f\" % intensity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, of the 49 events we have characterised, most are category 1 (Moderate), while only 2 are category 2 (Strong). We recorded no severe or extreme events. Lets now plot these heatwaves zones on our time series. We will scale the heatwaves zones colour according to category, but you can change this to intensity, or any parameter you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = np.array(heatwaves[tag][\"mhws\"].intensity_max)\n",
    "categories = np.array(heatwaves[tag][\"mhws\"].category)\n",
    "\n",
    "# change \"categories\" to \"\n",
    "scalings = categories.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make our final interactive plot, showing our final result! If you explore the plot; you should be able to find all 31 events, with the stronger intensity events in a \"redder\" shaded colour. By all means re-run this using intensity or another parameter as a scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the heatwaves zones\n",
    "t_values = np.union1d(heatwaves[tag][\"mhws\"].index_start.values, heatwaves[tag][\"mhws\"].index_end.values)\n",
    "norm_scalings = (scalings - min(0, np.nanmin(scalings)))/(np.nanmax(scalings) - min(0, np.nanmin(scalings)))\n",
    "\n",
    "for t1, t2, scaling, norm_scaling in zip(*[iter(t_values)] * 2, scalings, norm_scalings):\n",
    "    plot_MWH_zone(p_MHW, t1, t2, heatwaves[tag][\"time_series\"], scaling, norm_scaling)\n",
    "\n",
    "# Add the legend & plot\n",
    "legend = bm.Legend(items=[(f\"SST [{tag}]\", [p_sst]), (f\"Seasonal climatology [{tag}]\", [p_seas]),\n",
    "        (f\"90% MHW detection threshold\", [p_thresh])], location=\"top_left\", ncols=1)\n",
    "\n",
    "p_MHW.add_layout(legend, \"center\")\n",
    "bi.show(p_MHW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section8'></a>8. Conclusions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have used the Hobday et al. (2016) [[5]](#ref5) based `xmhw` package, to identify marine heat waves in a small region of the western Mediterannean Sea, using a time series of sea surface temperature. Recent research suggests that the frequency of marine heatwaves is increasing [[6]](#ref6), and that their occurence further exacerbates existing climate change impacts in both physical [[7]](#ref7) and bioligical [[8]](#ref8) systems. Satellites provide essential inputs to the global, gridded SST records thet we need to monitor marine ecosystems and conduct these analyses, especially when they are derived from high-quality measurements, such as those available from Sentinel-3 SLSTR.\n",
    "\n",
    "### Suggested next steps\n",
    "\n",
    "* We showed in [Section5](#section5) that different SST records give us subtlely different climatologies. Try changing the analysis to OSTIA in [Section6](#section6) to see if your heatwave record changes.\n",
    "* Although near real-time data sets are not as high quality, they do allow us to look at more recent events. Try changing your OSTIA source to the NRT data feed () and adapt the acquition dates and tag in [Section6](#section6) to look at more recent events.\n",
    "* Adapt the notebook for any region you choose, but bear in mind that the larger the region, the more time it will take to gather the data (selecting a whole ocean basin, or the entire globe is not advisable!)\n",
    "* Change the analysis period, to see how the climatology definition alters your heatwave record.\n",
    "* If you wish to learn more about the level-2 SLSTR data, and see recent examples of high resolution anomalies, please see the linked example <a href=\"../Atl_Med_anomalies/Atlantic_Med_SST_anomalies.ipynb\"  target=\"_blank\">Sea surface temperature anomalies and trends in the Northern Atlantic and Mediterranean Sea</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<br>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:.training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "content_type": "Software & code",
  "data_access": [
   "WEkEO",
   "CMEMS"
  ],
  "deployment": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-case-studies/HEAD?labpath=Case_studies%2FCSM_ocean%2FMed_MHW_2023%2FMed_MHW.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/blob/main/Case_studies/CSM_ocean/Med_MHW_2023/Med_MHW.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "https://github.com/wekeo/ocean-case-studies/blob/main/Case_studies/CSM_ocean/Med_MHW_2023/Med_MHW.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/CSM_ocean/Med_MHW_2023/Med_MHW.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "description": "This Jupyter Notebook shows investigates marine heat waves in the Mediterranean Sea in 2023 using sea surface temperature data from Sentinel-3 SLSTR and the CMEMS OSTIA product.",
  "image": "../../../img/thumbs/Med_MHW_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "license": "MIT",
  "metadata_schema_version": "2.0.0",
  "originator": "EUMETSAT",
  "tags": {
   "data_provider": "CMEMS",
   "orbit": "LEO",
   "satellite": [
    "ESA SST CCI and C3S reprocessed sea surface temperature",
    "Global ocean reprocessed OSTIA sea surface temperature"
   ],
   "sensor": "Multisensor",
   "service": "",
   "subtheme": "Climate system monitoring - Ocean",
   "theme": "Marine",
   "variable": "Sea surface temperature"
  },
  "title": "Exploring North Atlantic and Mediterranean marine heatwaves using SST",
  "version": "2.0.0",
  "version_date": "2024-09-02"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
