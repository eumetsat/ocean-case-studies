


























import datetime                           # a library that allows us to work with dates and times
import eumdac                             # a tool that helps us download via the eumetsat/data-store
import fnmatch                            # a library that allows us to filter for file types
import getpass                            # a library to help us enter passwords
import glob                               # a library that aids in searching for files
import matplotlib.pyplot as plt           # a library that support plotting
import os                                 # a library that allows us access to basic operating system commands
from pathlib import Path                  # a library to help us to construct system paths
import shutil                             # a library that allows us access to basic operating system commands like copy
import time                               # a library that helps us manage script timing
import warnings                           # a library that helps us handle warnings
import xarray as xr                       # a library that supports the use of multi-dimensional arrays in Python
from xcube.webapi.viewer import Viewer    # a library that provides the Xcube viewer

# turn off any script warnings
warnings.filterwarnings('ignore')





# Acqua Alta location
lat = 45.31435
lon = 12.508317

# size of the box we want to acquire around the location of interest
spatial_tolerance = 0.25





collectionID_OPE = "EO:EUM:DAT:0407"
collectionID_REP = "EO:EUM:DAT:0556"





timeliness = "NT"





# set the first scene to process
scene_start = 17

# set the number of scenes from the first scene to process
nscenes = 8





download_data = True











# load credentials
eumdac_credentials_file = Path(Path.home() / '.eumdac' / 'credentials')

if os.path.exists(eumdac_credentials_file):
    consumer_key, consumer_secret = Path(eumdac_credentials_file).read_text().split(',')
else:
    # creating authentication file
    consumer_key = input('Enter your consumer key: ')
    consumer_secret = getpass.getpass('Enter your consumer secret: ')
    try:
        os.makedirs(os.path.dirname(eumdac_credentials_file), exist_ok=True)
        with open(eumdac_credentials_file, "w") as f:
            f.write(f'{consumer_key},{consumer_secret}')
    except:
        pass
        
token = eumdac.AccessToken((consumer_key, consumer_secret))
print(f"This token '{token}' expires {token.expiration}")





datastore = eumdac.DataStore(token)








# Use collection ID
collection_OPE = datastore.get_collection(collectionID_OPE)
collection_REP = datastore.get_collection(collectionID_REP)





for collection in [collection_OPE, collection_REP]:
    print(f"{collection.title}\n---\n{collection.abstract}\n")





# make a very small box around our proposed location
ROI = [[lon - spatial_tolerance, lat - spatial_tolerance],
       [lon - spatial_tolerance, lat + spatial_tolerance],
       [lon + spatial_tolerance, lat + spatial_tolerance],
       [lon + spatial_tolerance, lat - spatial_tolerance],
       [lon - spatial_tolerance, lat - spatial_tolerance]]

# convert this to a WKT polygon
polygon = 'POLYGON(({}))'.format(','.join(["{} {}".format(*coord) for coord in ROI]))

# search for our products
products_OPE = collection_OPE.search(geo=polygon, timeliness=timeliness)
products_REP = collection_REP.search(geo=polygon, timeliness=timeliness)





print(f"Found {len(products_REP)} reprocessed products")
print(f"Found {len(products_OPE)} operational products")








latest = products_REP.first()
file_tags = str(latest).split('_')
file_tags = [i for i in file_tags if i]
latest_date = file_tags[4]
print(f"The last available reprocessing products is at {latest_date}")

products_OPE = collection_OPE.search(geo=polygon,
                                     dtstart=datetime.datetime.strptime(latest_date, "%Y%m%dT%H%M%S") + datetime.timedelta(seconds=1),
                                     timeliness=timeliness)

print(f"Found {len(products_OPE)} matching products that occur after the end of the reprocessing")








# first we convert our REP search results to a product list so that we can concatenate the two records
final_products_REP = [item for item in products_REP]
final_products_OPE = [item for item in products_OPE]

# then we concatenate the lists
final_products = final_products_OPE + final_products_REP





print(f"The last available reprocessed product is:\n{str(final_products_REP[0])}")
print(f"The first available operational product is:\n{str(final_products_OPE[-1])}")











datatailor = eumdac.DataTailor(token)





# Defining the chain configuration
chain = eumdac.tailor_models.Chain(
    product='OLL2WFR',
    roi={"NSWE" : [lat+spatial_tolerance, lat-spatial_tolerance, lon-spatial_tolerance, lon+spatial_tolerance]},
    filter={"bands" : ["chl_nn"]},
    projection='geographic',
    resample_resolution=[0.003, 0.003],
    format='netcdf4'
)





# select a few products for our example
selected_products = final_products[scene_start:scene_start+nscenes]





if download_data:
    
    sleep_time = 10
    
    for product in selected_products:
    
        print(f"Customising {product}")
        customisation = datatailor.new_customisation(product, chain=chain)
        status = customisation.status
        
        # Monitor the customisation
        while status:
            # Get the status of the ongoing customisation
            status = customisation.status
        
            if "DONE" in status:
                print(f"Customisation {customisation._id} is successfully completed.")
                break
            elif status in ["ERROR","FAILED","DELETED","KILLED","INACTIVE"]:
                print(f"Customisation {customisation._id} was unsuccessful. Customisation log is printed.\n")
                print(customisation.logfile)
                break
            elif "QUEUED" in status:
                print(f"Customisation {customisation._id} is queued.")
            elif "RUNNING" in status:
                print(f"Customisation {customisation._id} is running.")
            time.sleep(sleep_time)
    
        # Download
        print(f"Customisation {customisation._id} outputs downloading.")
        nc, = fnmatch.filter(customisation.outputs, '*.nc') 
    
        with customisation.stream_output(nc,) as stream, \
            open(stream.name, mode='wb') as fdst:
            shutil.copyfileobj(stream, fdst)
    
        # Tidy up (if successful)
        print(f"Customisation {customisation._id} outputs cleared.")
        customisation.delete()








downloaded_files = sorted(glob.glob("OLL2*"))
times = [datetime.datetime.strptime(downloaded_file.split('_')[1],"%Y%m%dT%H%M%SZ") for downloaded_file in downloaded_files]





ds = xr.open_mfdataset(downloaded_files, combine='nested', concat_dim="time")
ds["time"] = times





viewer = Viewer(
    server_config={
        "Styles": [
            {
                "Identifier": "CHL",
                "ColorMappings": {
                    "chl_nn": {"ValueRange": [-2, 2], "ColorBar": "viridis"}
                },
            }
        ]
    }
)





viewer.add_dataset(ds, style="CHL");





viewer.show()















