























import glob                            # a package that helps with file searching
import os                              # a library that allows us access to basic operating system commands
import eumdac                          # a tool that helps us download via the eumetsat/data-store
import datetime                        # a library that allows us to work with dates and times
import shutil                          # a library that allows us access to basic operating system commands like copy
import cartopy                         # a library that supports mapping and projection
import matplotlib as mpl               # a library the provides plotting capability
import matplotlib.pyplot as plt        # a library the provides plotting capability
import xarray as xr                    # a library that helps us work efficiently with multi-dimensional arrays
import numpy as np                     # a library that lets us work with arrays; we import this with a new name "np"
import pandas                          # a library the support times series management
import cv2                             # a library for making videos
import IPython.display                 # a library that supports playing video
from owslib.wms import WebMapService   # a library that supports interfacing with OGC web services
from owslib.util import Authentication # a library that supports authenticating OGC web services
import requests                        # a library that supports HTTP
from pathlib import Path               # a library to help us to construct system paths
import getpass                         # a library to help us enter passwords
import warnings                        # a library that supports managing warning messages

warnings.filterwarnings("ignore")








storm_name = "FREDDY"
storm_year = "2023"
knots_to_kmh = 1.852
make_annotations = True





# Altimetry parameters: S3
download_S3_data = True
S3_timeliness = "NT"

# Altimetry parameters: S6
download_S6_data = True
S6_timeliness = "NT"

day_pad = 1





bathy_file = None
plot_WMS = True
WMS_layers = "mumi:wideareacoverage_rgb_airmass"





# the minimum and maximum wind speed (in km/h) to plot. Any values above the maximum will be truncated
wind_min = 0
wind_max = 150

# the size of the plot. We advise retaining these numbers, and at the very least, this plot ratio.
plot_xy = [32, 12]

# the scaling parameter to map extent in nautical miles to plot pixels. As explained above,
# will change with each map projection.
rad_scale = 2000/60
rad_edgewidth = 10

# the altimetry search window for displaying tracks
time_window = [6, 6]

# the latitude and longitude extent of your plot
plot_extents = [-180, 180, -90, 90]

# any annotations you wish to make on your plot in the form shown in the example below
annots = {}

# get a "land layer" map to use in plotting
land_50m = cartopy.feature.NaturalEarthFeature('physical', 'land', '10m',
                                        edgecolor='face',
                                        facecolor=cartopy.feature.COLORS['land'])

# how often to output an animation panel
panel_frequency = 5





# Example cases
if storm_name == "NANMADOL" or storm_name == "HINNAMNOR":
    # plot extents: [W, E, S, N]
    plot_extents = [111, 160, 18, 43]
    # plot annotations
    annots = {"names":["Japan", "South\nKorea", "China"], "xs":[137.0, 127.0, 115.0], "ys":[35.75, 35.75, 31.0]}
elif storm_name == "FIONA" or storm_name == "IAN" or storm_name == "FRANKLIN" or storm_name == "LEE":
    plot_extents = [-90, -6, 0, 43]
    annots = {"names":["N. America", "S. America", "Africa"], "xs":[-87.5, -70, -12.5], "ys":[35, 5, 15]}
elif storm_name == "FREDDY":
    plot_extents = [26, 120, -40, 8]
    annots = {"names":[], "xs":[], "ys":[]}

# set plotting parameters
xoffset = (plot_extents[1] - plot_extents[0])
yoffset = (plot_extents[3] - plot_extents[2])











if bathy_file:
    bathy_stride = 3
    BATHY_vars = xr.open_mfdataset(bathy_file)
    blon = np.array(BATHY_vars.lon)[::bathy_stride]
    blat = np.array(BATHY_vars.lat)[::bathy_stride]
    bathy = np.array(BATHY_vars.elevation)[::bathy_stride, ::bathy_stride]
    BATHY_vars.close()








remote_tracks_file = "https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/netcdf/IBTrACS.last3years.v04r00.nc"
local_tracks_file = os.path.join(os.getcwd(), 'IBTrACS.nc')

with requests.get(remote_tracks_file, stream=True) as r:
    with open(local_tracks_file, 'wb') as f:
        shutil.copyfileobj(r.raw, f)





tracks = xr.open_mfdataset(local_tracks_file)
tracks





# find the correct storm for the correct year
name_ix = np.where(np.array(tracks["name"]).astype(str) == storm_name)
storm_dates = np.array(tracks["iso_time"])[name_ix].astype(str)
storm_years = np.array([str(i[0][0:4]) for i in storm_dates])
year_ix = np.where(storm_years == storm_year)[0]

# get relevant coordinates
lon = np.array(tracks["lon"])[name_ix][year_ix]
lat = np.array(tracks["lat"])[name_ix][year_ix]
date = np.array(tracks["iso_time"])[name_ix][year_ix].astype(str)
intensity = np.array(tracks["usa_wind"])[name_ix][year_ix] * knots_to_kmh
radius = np.array(tracks["usa_roci"])[name_ix][year_ix]
tracks.close()





# strip empties
ii = np.where(date != '')
lon = lon[ii]
lat = lat[ii]
date = date[ii]
intensity = intensity[ii]
radius = radius[ii]





radius = radius*rad_scale - rad_edgewidth*2





# format data in pandas
storm_dates = pandas.to_datetime(date)





# set altimetry acquision spatial window: W, E, S, N
north = np.nanmax(lat)
south = np.nanmin(lat)
east = np.nanmax(lon)
west = np.nanmin(lon)

ROI = [[west, south], [west, north], [east, north], [east, south], [west, south]]
polygon = 'POLYGON(({}))'.format(','.join(["{} {}".format(*coord) for coord in ROI]))

start = storm_dates[0] - datetime.timedelta(days=day_pad)
end = storm_dates[-1] + datetime.timedelta(days=day_pad)








# Create a download directory for our SRAL products
download_dir = os.path.join(os.getcwd(), f"products_{storm_name}")
os.makedirs(download_dir, exist_ok=True)





# summarise
print(f'Getting swaths from {str(start)} to {str(end)} over region: {str(polygon)}')





# load credentials
eumdac_credentials_file = Path(Path.home() / '.eumdac' / 'credentials')

if os.path.exists(eumdac_credentials_file):
    consumer_key, consumer_secret = Path(eumdac_credentials_file).read_text().split(',')
else:
    # creating authentication file
    consumer_key = input('Enter your consumer key: ')
    consumer_secret = getpass.getpass('Enter your consumer secret: ')
    try:
        os.makedirs(os.path.dirname(eumdac_credentials_file), exist_ok=True)
        with open(eumdac_credentials_file, "w") as f:
            f.write(f'{consumer_key},{consumer_secret}')
    except:
        pass
        
token = eumdac.AccessToken((consumer_key, consumer_secret))
print(f"This token '{token}' expires {token.expiration}")





datastore = eumdac.DataStore(token)





for collection in datastore.collections:
    if "SRAL" in collection.title and "non-public" not in collection.abstract:
        print(f"{collection}: {collection.title}")





collectionID_S3 = 'EO:EUM:DAT:0834'





selected_collection = datastore.get_collection(collectionID_S3)





# filter the collection for products that match our storm
products = selected_collection.search(dtstart=start, dtend=end, geo=polygon, timeliness=S3_timeliness)
print(f'Found {str(len(products))} products')





# download
if download_S3_data:
    for product in products:
        for entry in product.entries:
            if 'standard_measurement' in entry:
                product_dir = os.path.join(download_dir, str(product)) 
                os.makedirs(product_dir, exist_ok=True)
                if os.path.exists(os.path.join(product_dir, os.path.basename(entry))):
                    print(f'Skipping existing file.')
                else:
                    with product.open(entry=entry) as fsrc, open(os.path.join(product_dir, fsrc.name), mode='wb') as fdst:
                        shutil.copyfileobj(fsrc, fdst)
                        print(f'Download of file {os.path.join(os.path.basename(product_dir), fsrc.name)} finished.')





# select the collection
collectionID_S6 = 'EO:EUM:DAT:0855'
selected_collection = datastore.get_collection(collectionID_S6)

# filter the collection for products that match our storm
products = selected_collection.search(dtstart=start, dtend=end, geo=polygon, timeliness=S6_timeliness)
print(f'Found {str(len(products))} products')





# download
if download_S6_data:
    for product in products:
        for entry in product.entries:
            if '_RED_' in entry:
                product_dir = os.path.join(download_dir, str(product)) 
                os.makedirs(product_dir, exist_ok=True)
                if os.path.exists(os.path.join(product_dir, os.path.basename(entry))):
                    print(f'Skipping existing file.')
                else:
                    with product.open(entry=entry) as fsrc, open(os.path.join(product_dir, fsrc.name), mode='wb') as fdst:
                        shutil.copyfileobj(fsrc, fdst)
                        print(f'Download of file {os.path.join(os.path.basename(product_dir), fsrc.name)} finished.')








if plot_WMS:
    service_url = 'https://view.eumetsat.int/geoserver/ows?'
    wms = WebMapService(service_url, auth=Authentication(verify=True))

    # set image parameters
    format_option = 'image/jpeg'
    x_pixels = 2000

    # set coords
    plot_ratio = (plot_extents[1] - plot_extents[0])/ (plot_extents[3] - plot_extents[2])
    lons = np.linspace(plot_extents[0], plot_extents[1], int(x_pixels))
    lats = np.linspace(plot_extents[2], plot_extents[3], int(x_pixels/plot_ratio))
    WMS_LONS, WMS_LATS = np.meshgrid(lons, lats)








# find the products
product_dirs_S3 = glob.glob(os.path.join(download_dir, "*.SEN3"))
product_dirs_S6 = glob.glob(os.path.join(download_dir, "*.SEN6"))





# loop through granules to get their average time stamps
granule_dates_S3 = []
for product_dir in product_dirs_S3:
    t_step = datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-14], "%Y%m%dT%H%M%S") \
           - datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-15], "%Y%m%dT%H%M%S")
    granule_dates_S3.append(datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-15], "%Y%m%dT%H%M%S") \
                         + t_step/2)





# loop through granules to get their average time stamps
granule_dates_S6 = []
for product_dir in product_dirs_S6:
    t_step = datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-11], "%Y%m%dT%H%M%S") \
           - datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-12], "%Y%m%dT%H%M%S")
    granule_dates_S6.append(datetime.datetime.strptime(os.path.basename(product_dir).split('_')[-12], "%Y%m%dT%H%M%S") \
                         + t_step/2)





product_dirs = np.array(product_dirs_S3 + product_dirs_S6)
granule_dates = np.array(granule_dates_S3 + granule_dates_S6)








# Create an output directory for our images products
output_dir = os.path.join(os.getcwd(), f"output_{storm_name}")
os.makedirs(output_dir, exist_ok=True)





# make the animation frames
for storm_date, count in zip(storm_dates, range(len(storm_dates))):

    if np.mod(count, panel_frequency) == 0:
        print(f"Processing data for {storm_date} (panel {str(count).zfill(2)})")
    else:
        continue
        
    # limit to plot region
    if lon[count] < np.nanmin(plot_extents[0]) or lon[count] > np.nanmax(plot_extents[1]) \
      or lat[count] < np.nanmin(plot_extents[2]) or lat[count] > np.nanmax(plot_extents[3]):
        continue

    # Step 1: set up the figure
    fig, [m, m2] = plt.subplots(2, 1, figsize=(plot_xy[0], plot_xy[1]),
                                dpi=150, gridspec_kw={'height_ratios': [14, 1]},
                                subplot_kw={"projection": cartopy.crs.PlateCarree()})
    plt.rcParams.update({'font.size': 20})
    m2.set_visible(False)

    # Bathy
    if bathy_file:
        m.contour(blon, blat, bathy,
            [-4000, -3000, -2000, -1000, -500, -100, 0],
            linewidths=0.5, linestyles='solid', cmap=plt.cm.Blues_r, alpha=0.75, zorder=1)

    # Plot land
    m.add_feature(land_50m, edgecolor='k', facecolor='k', zorder=2)
    
    # Step 2: Plot WMS layers
    if plot_WMS:
        t_format = '%Y-%m-%dT%H:%M:%S.000Z'
        payload = {'service' : 'WMS',
                    'access_token' : token,
                    'request' : 'GetMap',
                    'version' : '1.3.0',
                    'layers' : WMS_layers, 
                    'format' : format_option,
                    'crs' : 'EPSG:4326',
                    'bbox' : f'{plot_extents[2]},{plot_extents[0]},{plot_extents[3]},{plot_extents[1]}',
                    'width' : int(x_pixels),  
                    'height' : int(x_pixels/plot_ratio), 
                    'time': datetime.datetime.strftime(storm_date, t_format)}
        req = requests.get(service_url, params=payload, stream=True).raw
        data = plt.imread(req, 0)
        
        m.pcolormesh(WMS_LONS, WMS_LATS[::-1], data, cmap=plt.cm.Reds, transform=cartopy.crs.PlateCarree(),
                     alpha=0.5, zorder=3)

    # Step 3: plot the historical hurricane track and latest position   
    track1 = m.scatter(lon[0:count+1], lat[0:count+1], radius[0:count+1], facecolors='none',
                       edgecolors=plt.cm.Purples((intensity[0:count+1]-wind_min)/(wind_max-wind_min)),
                       alpha=0.5, zorder=4, linewidths=rad_edgewidth)
    
    m.scatter(lon[count], lat[count], radius[count], facecolors='none',
              edgecolors=plt.cm.Purples((intensity[count]-wind_min)/(wind_max-wind_min)),
              zorder=5, linewidths=rad_edgewidth)
    
    m.set_extent(plot_extents, crs=cartopy.crs.PlateCarree())

    if lon[count] + xoffset/4 > plot_extents[1]:
        plot_lon = lon[count] - xoffset/4
    else:
        plot_lon = lon[count] + xoffset/10

    if lat[count] + yoffset/4 > plot_extents[3]:
        plot_lat = lat[count] - yoffset/4
    else:
        plot_lat = lat[count] + yoffset/10

    if make_annotations:
        m.annotate(storm_name, xy=(lon[count], lat[count]), xycoords='data',
                   xytext=(plot_lon, plot_lat), textcoords='data',
                   arrowprops=dict(arrowstyle="->", connectionstyle="arc3"),
                   color='k', zorder=100, fontsize=14)

    # Step 4: find and plot the altimetry tracks in this time window
    tmin = storm_date - datetime.timedelta(hours=time_window[0])
    tmax = storm_date + datetime.timedelta(hours=time_window[1])
    ii = list(set(np.where(granule_dates >= tmin.to_pydatetime())[0])
              .intersection(np.where(granule_dates < tmax.to_pydatetime())[0]))

    for product_dir, granule_date in zip(product_dirs[ii], granule_dates[ii]):
        print(product_dir)
        # read data
        if "SEN3" in product_dir:
            # Sentinel-3 SRAL branch (no netCDF groups)
            ds = xr.open_dataset(os.path.join(product_dir, 'standard_measurement.nc'))
            plot_var = np.array(ds.swh_ocean_01_ku)
            flags = np.array(ds.swh_ocean_qual_01_ku).astype(float) + np.array(ds.surf_type_01).astype(float)
            alon = ds["lon_01"]
            alat = ds["lat_01"]
        else:
            # Sentinel-6 branch (with netCDF groups)
            input_file = glob.glob(os.path.join(product_dir, '*.nc'))[0]
            ds = xr.open_dataset(input_file, group="data_01", decode_times=False)
            dsc = xr.open_dataset(input_file, group="data_01/ku", decode_times=False)
            plot_var = np.array(dsc.swh_ocean)
            flags = np.array(dsc.swh_ocean_qual).astype(float)+np.array(ds.surface_classification_flag).astype(float)
            alon = ds['longitude']
            alat = ds['latitude']
            alon[flags != 0.0] = np.nan
            alat[flags != 0.0] = np.nan
            m.scatter(alon, alat, c='0.5', s=200, zorder=6)
            dsc.close()

        ds.close()
        plot_var[flags != 0.0] = np.nan
        p_alt = m.scatter(alon, alat, c=plot_var, s=100,
                          cmap=plt.cm.RdYlBu_r, marker='o', edgecolors=None, 
                          linewidth=0.0, vmin=0.0, vmax=7.0, zorder=7)

    # Step 5: annotate this plot
    if make_annotations and 'annots' in locals():
        for name, x_loc, y_loc in zip(annots["names"], annots["xs"], annots["ys"]):  
            m.annotate(name, xy=(x_loc, y_loc), color='0.25', zorder=100, fontsize=18)

    if make_annotations:
        # Step 6: embellish this plot
        g1 = m.gridlines(draw_labels = True, zorder=1000, color='0.0', linestyle='--', linewidth=0.5)
        g1.top_labels = False
        g1.right_labels = False
        g1.xlabel_style = {'color': 'black'}
        g1.ylabel_style = {'color': 'black'}
        m.set(facecolor = "1.0")
        m.annotate(str(storm_date.date())+' '+str(storm_date.time()), (0.00, -0.0775), xycoords='axes fraction')

        # Step 7: make SWH and wind speed colour bars
        if 'p_alt' in locals():
            cb_ax = fig.add_axes([m.get_position().x0, 0.126,
                                  m.get_position().width * 0.475, 0.025])
            fig.colorbar(p_alt, cax=cb_ax, orientation="horizontal", label='Significant wave height [m]')
    
        cb_ax2 = fig.add_axes([m.get_position().x0 + m.get_position().width*0.525, 0.126,
                               m.get_position().width * 0.475, 0.025])
        fig.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.Purples,
                                           norm=mpl.colors.Normalize(vmin=wind_min, vmax=wind_max)),
                     cax=cb_ax2, orientation="horizontal", label='Maximum sustained wind speed [km/h]')

    # Step 8: save and close figure
    plt.savefig(os.path.join(output_dir, f"panel{str(count).zfill(4)}.png"), bbox_inches='tight')
    plt.close(fig)








video_name = f"SWH_animation_{storm_name}.mp4"
fps = 5.0





# find all the images
images = sorted(glob.glob(os.path.join(output_dir, "*.png")))

# use first image to define extents
frame = cv2.imread(images[0])
height, width, layers = frame.shape

# define the output codec and size
fourcc = cv2.VideoWriter_fourcc(*'avc1')
video = cv2.VideoWriter(video_name, fourcc, fps, (width, height))

# compile and contatenate the images
for image in images:
    video.write(cv2.imread(image))

# clear the memory
cv2.destroyAllWindows()
video.release()








IPython.display.HTML(f"""
<video autoplay loop width=100% height=100% controls>
  <source src="{video_name}" type="video/mp4">
</video>
""")






