


























import cartopy                        # a library that supports mapping and projection
import datetime                       # a library that allows us to work with dates and times
import glob                           # a package that helps with file searching
import matplotlib.pyplot as plt       # a library the provides plotting capability
import numpy as np                    # a library that lets us work with arrays; we import this with a new name "np"
import os                             # a library that allows us access to basic operating system commands
import shutil                         # a library that allows us access to basic operating system commands like copy
import xarray as xr                   # a powerful library that helps us work efficiently with multi-dimensional arrays
import zipfile                        # a library that allows us to unzip zip-files.
import eumartools                     # a library that helps us work with Sentinel-3 data
import hda                            # a library for downloading via wekeo
import warnings                       # a library the helps us to manage warnings
import copernicusmarine               # a library to help us access CMEMS data
from pathlib import Path              # a library to help us to construct system paths
import getpass                        # a library to help us enter passwords

warnings.filterwarnings("ignore")
plt.rcParams.update({'font.size': 12})





from xmhw.xmhw import detect, threshold





# Create a download and precomputed directory for our SLSTR and CMEMS products
download_dir = os.path.join(os.getcwd(), "products")
os.makedirs(download_dir, exist_ok=True)

precomputed_dir = os.path.join(os.getcwd(), "precomputed")
os.makedirs(precomputed_dir, exist_ok=True)





# Should we download new data?
download_data = True

# plot region for SLSTR data: W, E, S, N
plot_region = [142.0, 156.0, -25.0, -10.0]

# sub-sampling for SLSTR pre-processing: default = 1 implies no subsampling 
plot_data_subsample = 1

# OSTIA MHW region W, S, E, N
CMEMS_dataset_id = "METOFFICE-GLO-SST-L4-REP-OBS-SST"
CMEMS_dataset_variables = ["analysed_sst"]
MHW_region = [147.0, -18.0, 148.0, -17.0]
start_year, end_year = [1992, 2022]








def process_SST_granule(SST_file, region, subsample=1, quality_level=4):
    """
    Quick function to process Level-2 SLSTR granules for memory management. 
    Regionally subsets, applies bias and masks out values lower than the quality level.

    Args:
        SST_file (string)        : the file to process
        region (list)            : the area subset to use when extracting data
        subsample (int)          : the grid subsampling parameter
        quality_level (int)      : the quality level to flag SLSTR data at. Anything lower than this value 
                                   will be discarded
    Returns:
        lon (array)              : the extracted longitude
        lat (array)              : the extracted latitude
        bias_corr_QC_SST (array) : the extracted, bias corrected, quality flagged SST

    """
    K_to_C = 273.15
    
    SST_data = xr.open_dataset(SST_file)

    ext_x, ext_y, ext_mask = eumartools.subset_image(SST_data["lon"][::subsample,::subsample],
                                                     SST_data["lat"][::subsample,::subsample], 
                                                     [region[0], region[1], region[1], region[0]],
                                                     [region[2], region[2], region[3], region[3]],
                                                     mode='global')
    
    ext_x = [i * subsample for i in ext_x] ; ext_y = [i * subsample for i in ext_y]
    minx = np.nanmin(ext_x) ; maxx = np.nanmax(ext_x) ; miny = np.nanmin(ext_y) ; maxy = np.nanmax(ext_y) 

    bias_corr_QC_SST = np.squeeze(
                       np.array(SST_data["sea_surface_temperature"][0,miny:maxy:subsample,minx:maxx:subsample]
                              + SST_data["sses_bias"][0,miny:maxy:subsample,minx:maxx:subsample] - K_to_C))

    flags = np.squeeze(np.array(SST_data["quality_level"][0,miny:maxy:subsample,minx:maxx:subsample]))
    bias_corr_QC_SST[flags < 4] = np.nan

    lon = np.squeeze(np.array(SST_data["lon"][miny:maxy:subsample,minx:maxx:subsample]))
    lat = np.squeeze(np.array(SST_data["lat"][miny:maxy:subsample,minx:maxx:subsample]))
    SST_data.close()

    return lon, lat, bias_corr_QC_SST








# Default location expected by hda package
wekeo_credentials_file = Path(Path.home() / '.hdarc')

# Create it only if it does not already exists
if not wekeo_credentials_file.is_file():
    USERNAME = input('Enter your username: ')
    PASSWORD = getpass.getpass('Enter your password: ')

    with open(wekeo_credentials_file, 'w') as f:
        f.write(f'user:{USERNAME}\n')
        f.write(f'password:{PASSWORD}\n')

c = hda.Client()








query = {
"dataset_id": "EO:EUM:DAT:SENTINEL-3:SL_2_WST___",
"bbox": [plot_region[0], plot_region[2], plot_region[1], plot_region[3]],
"dtstart": "2021-12-22T12:37:36.000Z",
"dtend": "2021-12-22T12:37:37.000Z",
"type": "SL_2_WST___"
}





if download_data:
    matches = c.search(query)
    for match in matches.results:
        fdst = f"{match['id']}.zip"
        print(f"Found: {fdst}")





if download_data:
    for match in matches:
        fdst = f"{match.results[0]['id']}.zip"

        print(f"Downloading and processing: {fdst}")
        match.download()

        # Unzip the product
        with zipfile.ZipFile(fdst, 'r') as zip_ref:
            zip_ref.extractall(download_dir)
            print(f'Unzipping of product {fdst} finished.')
            os.remove(fdst)

        # process downloaded file
        SST_file = glob.glob(os.path.join(download_dir, fdst.replace(".zip",""), "*.nc"))[0]
        OUT_file = os.path.join(precomputed_dir, fdst.replace('.SEN3.zip','_subset.nc'))
        lon, lat, sst = process_SST_granule(SST_file, plot_region, subsample=plot_data_subsample)
        
        # write to new netCDF file
        ds = xr.Dataset({"sst": (("x", "y"), sst)},
                        coords={"lat": (("x", "y"), lat), 
                                "lon": (("x", "y"), lon)})
        ds.to_netcdf(OUT_file, format='NETCDF4_CLASSIC')

        # remove full size download
        shutil.rmtree(os.path.join(download_dir, fdst.replace(".zip","")))








# get the files
SLSTR_files = glob.glob(os.path.join(precomputed_dir, '*.nc'))





# setup figure
fig, m = plt.subplots(1, 1, figsize=(10, 14), dpi=300, subplot_kw={"projection": cartopy.crs.PlateCarree()})

# setup plot 1: the composite
m.set_extent(plot_region)

# make the plot: we will call this as a function as it contains a 'for' loop to iterate over our SLSTR granules.
for SLSTR_file in SLSTR_files:
    # plot the SST field
    SST_data = xr.open_dataset(SLSTR_file)
    p1 = m.pcolormesh(SST_data["lon"], SST_data["lat"],
                      SST_data["sst"], cmap=plt.cm.RdYlBu_r,\
                      vmin=27, vmax=30, zorder=1)
    SST_data.close()

# add some map embellishments
m.add_feature(cartopy.feature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='k', facecolor='#546d51', linewidth=0.5))
g1 = m.gridlines(draw_labels = True, linestyle='--', linewidth=0.5, zorder=1000)
g1.top_labels = g1.right_labels = False
g1.xlabel_style = g1.ylabel_style = {'color': '0.5'}

# add a colour bar
cbar = fig.colorbar(p1, ax=m, location='bottom', pad=0.05)
cbar.ax.tick_params() 
cbar.set_label('SLSTR night-time SST composite, 22 Dec 2021 [$^{o}$C]')
plt.savefig('SLSTR_composite_22122021.png', bbox_inches='tight')











# Default location expected by the copernicusmarine package
copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')

# Create it only if it does not already exists
if not copernicus_marine_credentials_file.is_file():
    copernicusmarine.login()





SST_data = copernicusmarine.open_dataset(
           dataset_id = CMEMS_dataset_id,
           variables=CMEMS_dataset_variables,
           minimum_longitude=MHW_region[0],
           maximum_longitude=MHW_region[2],
           minimum_latitude=MHW_region[1],
           maximum_latitude=MHW_region[3],
           start_datetime="{start_year}-01-01T00:00:00.000Z".format(start_year = start_year),
           end_datetime="{end_year}-12-31T00:00:00.000Z".format(end_year = end_year)
           )








SST_spatial_average = SST_data.mean(dim='latitude').mean(dim='longitude')
SST_annual_values = SST_spatial_average.groupby('time.year').mean('time')
SST_anomaly = SST_annual_values["analysed_sst"] - SST_annual_values["analysed_sst"].mean(dim="year")








# here we are dropping the final year, in case it is not complete!
SST_stripes = np.squeeze(np.array(SST_anomaly[:-1]))
SST_stripes_2D = np.repeat(SST_stripes[np.newaxis,...], 2, axis=0)





fig = plt.figure(figsize=(20, 10), dpi=300)

vmax = np.nanmax(abs(SST_stripes))

plt.pcolormesh(SST_stripes_2D, vmin=vmax*-1, vmax=vmax, cmap=plt.cm.RdBu_r)
plt.xticks(np.arange(len(SST_anomaly))+0.5, SST_anomaly.year.values, rotation=90)
plt.xlim([0,len(SST_anomaly)-1])
plt.yticks([],[])
cbar = plt.colorbar()
cbar.set_label('SST anomaly [$^{o}$C]')
plt.savefig('Climate_stripes_GBR.png', bbox_inches='tight')











times = [datetime.datetime.strptime(str(i), "%Y-%m-%dT%H:%M:%S.%f000").toordinal() 
           for i in np.asarray(SST_spatial_average["time"])]

doy = [datetime.datetime.strptime(str(i), "%Y-%m-%dT%H:%M:%S.%f000").timetuple().tm_yday - 1
       for i in SST_spatial_average["time"].values]

dates = [datetime.datetime.fromordinal(tt) for tt in times]





SST_time_series = SST_spatial_average["analysed_sst"] - 273.15
clim = threshold(SST_time_series)
mhws = detect(SST_time_series, clim['thresh'], clim['seas'])





n_events = len(mhws['event'])
print(f"Number of heatwaves: {n_events}")





plt.figure(figsize=(20, 10), dpi=300)

p1, = plt.plot(SST_spatial_average["time"], clim['seas'].values[doy], 'b--', linewidth=1, zorder=1)
p2, = plt.plot(SST_spatial_average["time"], clim['thresh'].values[doy], 'r', linewidth=1, zorder=2)
p3, = plt.plot(SST_spatial_average["time"], SST_time_series, 'k', linewidth=1, zorder=3)

# Find indices for previous MHW and shade
for ev0 in np.arange(n_events):
    t1 = np.where(SST_spatial_average["time"]==mhws['time_start'][ev0].values)[0][0]
    t2 = np.where(SST_spatial_average["time"]==mhws['time_end'][ev0].values)[0][0]
    if ev0 == n_events - 1:
        plot_col = 'r'
    else:
        plot_col = (1,0.6,0.5)
    plt.fill_between(np.array(dates[t1:t2+1]), clim['thresh'].values[doy][t1:t2+1], np.array(SST_time_series[t1:t2+1]), \
                     color=plot_col)

plt.xlim(SST_spatial_average["time"][-1000], SST_spatial_average["time"][-1])
plt.ylim(clim['seas'].min() - 1, clim['seas'].max() + 2)
plt.ylabel(r'SST [$^\circ$C]')
plt.legend([p1, p2, p3],["Seasonal climatology", "Threshold", "SST"], frameon=False)
plt.savefig('Marine_heat_waves_GBR.png', bbox_inches='tight')












