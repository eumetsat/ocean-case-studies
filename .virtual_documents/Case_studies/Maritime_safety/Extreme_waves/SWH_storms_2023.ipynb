


























import cartopy                         # a library that supports mapping and projection
import cartopy.crs as ccrs             # a library that supports mapping and projection
import copernicusmarine                # a library to help us access CMEMS data
import datetime                        # a library that allows us to work with dates and times
import eumdac                          # a tool that helps us download via the eumetsat/data-store
import getpass                         # a library to help us enter passwords
import glob                            # a library that helps us search for files
import json                            # a library that helps us make JSON format files
import matplotlib                      # a library the provides plotting capability
import matplotlib.pyplot as plt        # a library the provides plotting capability
from pathlib import Path               # a library that helps construct system path objects
import numpy as np                     # a library that lets us work with arrays; we import this with a new name "np"
import os                              # a library that allows us access to basic operating system commands
import shutil                          # a library that allows us access to basic operating system commands like copy
import warnings                        # a library that supports managing warning messages
import xarray as xr                    # a library that helps us work efficiently with multi-dimensional arrays
from xcube.webapi.viewer import Viewer # a library that provides the Xcube viewer
import zipfile                         # a library that support zipping/unzipping files

# turn off warnings and set fontsize
warnings.filterwarnings("ignore")
plt.rcParams.update({'font.size': 24})

# set Xcube server if running on WEkEO
if "WEKEO_DATABROKER_URL" in os.environ:
    os.environ["XCUBE_JUPYTER_LAB_URL"] = f"https://jupyterhub.prod.wekeo2.eu/user/{os.environ['JUPYTERHUB_USER']}/"





# defining our bounding box (W, E, S, N)
ROI = [-30.0, 0.0, 40.0, 55.0]

# make a WKT polygon string for this box
roi = [[ROI[0], ROI[2]], [ROI[1], ROI[2]], [ROI[1], ROI[3]], [ROI[0], ROI[3]], [ROI[0], ROI[2]]]
polygon = 'POLYGON(({}))'.format(','.join(["{} {}".format(*coord) for coord in roi]))

# defining out search times
start = datetime.datetime(2023, 11, 2, 0, 0)
end = datetime.datetime(2023, 11, 4, 23, 59)





# Download new L2 data or not?
download_l2_data = True

# our EUMETSAT Data Store collection
collectionID = 'EO:EUM:DAT:0415'

# our satellite of interest
satellite = "Sentinel-3B"

# the components we should download
components = ["reduced_measurement.nc", "enhanced_measurement.nc"]





CMEMS_productID = "cmems_mod_glo_wav_anfc_0.083deg_PT3H-i"
CMEMS_variables = ['VHM0']





# Create a download directory for our products
download_dir = os.path.join(os.getcwd(), "products")
os.makedirs(download_dir, exist_ok=True)











# load credentials
eumdac_credentials_file = Path(Path.home() / '.eumdac' / 'credentials')

if os.path.exists(eumdac_credentials_file):
    consumer_key, consumer_secret = Path(eumdac_credentials_file).read_text().split(',')
else:
    # creating authentication file
    consumer_key = input('Enter your consumer key: ')
    consumer_secret = getpass.getpass('Enter your consumer secret: ')
    try:
        os.makedirs(os.path.dirname(eumdac_credentials_file), exist_ok=True)
        with open(eumdac_credentials_file, "w") as f:
            f.write(f'{consumer_key},{consumer_secret}')
    except:
        pass
        
token = eumdac.AccessToken((consumer_key, consumer_secret))
print(f"This token '{token}' expires {token.expiration}")





datastore = eumdac.DataStore(token)





# list all SRAL collection IDs - if we don't know a priori which collection we are interested in (this can take a minute or so to run the first time). 
print(f"Collections found: {len(datastore.collections)}")

for collection_id in datastore.collections:
    if ("SRAL" in collection_id.title):
        if "non-public" in collection_id.abstract: continue
        print(f"Collection ID({collection_id}): {collection_id.title}")





selected_collection = datastore.get_collection(collectionID)





selected_collection.search_options





products = selected_collection.search(geo=polygon, sat=satellite, dtstart=start, dtend=end)

for product in products:
    print(product)





if download_l2_data:
    downloaded_components = []
    
    for product, count in zip(products, range(len(products))):
    
        product_download_directory = os.path.join(download_dir, str(product))
        os.makedirs(product_download_directory, exist_ok=True)
    
        # download the required product components
        for entry in product.entries:
            res = [ele for ele in components if(ele == os.path.basename(entry))]
            if res:
                with product.open(entry=entry) as fsrc, open(os.path.join(product_download_directory, fsrc.name),
                                                            mode='wb') as fdst:
                    downloaded_components.append(os.path.join(product_download_directory, fsrc.name))
                    print(f'Downloading ({count+1}/{len(products)}) {product}: {fsrc.name}.')
                    shutil.copyfileobj(fsrc, fdst)
else:
    downloaded_components = sorted(glob.glob(os.path.join(download_dir, "*", components[0])))











# select input file
s3_files = glob.glob(os.path.join(download_dir, 'S*', components[0]))

# We sort the files by "alphabetical" order (default), but pass numbers are also correctly ordered, which is our goal
# this sorting will provide with a well-orderer dataset/nc file (see next cell). 
s3_files.sort()

ds_s3 = xr.open_mfdataset(s3_files, combine='by_coords')





ds_s3





# load coordinates
lon_s3 = ds_s3['lon_01']
lat_s3 = ds_s3['lat_01']

# load the data ; we take the Significant Wave Height field at 1 Hz in Ku band, SAR-mode (plrm would do, too), over ocean surfaces.
swh_s3 = ds_s3['swh_ocean_01_ku']





ds_s3.close()





douglas_8 = np.where(swh_s3 > 9.0)
douglas_9 = np.where(swh_s3 > 14.0)





# make a figure
fig = plt.figure(figsize=(24,16), dpi=150)
ax = plt.axes(projection=ccrs.PlateCarree())

# decorate the figure
ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='gray', alpha=0.5, linestyle='--', zorder=100)
ax.set_extent(ROI, crs=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.LAND, linewidth=1, facecolor='lightgrey', edgecolor='k', zorder=1)

# plot and show the data
tracks_s3 = ax.scatter(lon_s3, lat_s3, c=swh_s3, s=50, vmin=0, vmax=15, marker='o', edgecolors=None, cmap="viridis", zorder=10)
p1 = ax.scatter(lon_s3[douglas_9], lat_s3[douglas_9], c="#7D3C98", s=1000, vmin=0, vmax=15, marker='o', edgecolors=None, zorder=9)
p2 = ax.scatter(lon_s3[douglas_8], lat_s3[douglas_8], c="#A569BD", s=500, vmin=0, vmax=15, marker='o', edgecolors=None, zorder=8)

# add a legend
plt.legend([p2, p1], ["V. high seas (DSS 8)", "Phenomenal seas (DSS 9)"], loc=4, labelspacing=1.5, facecolor='lightgrey', fontsize=20)

# add a colorbar 
cbar = plt.colorbar(tracks_s3, orientation="horizontal", pad=0.03)
cbar.set_label('Significant wave height [m]')

# annotate the tracks with their names
lat_avg = (ROI[2] + ROI[3])/2
for s3_file in s3_files:
    ds_s3 = xr.open_dataset(s3_file)
    ii = np.where(np.abs(ds_s3.lat_01 - lat_avg) == np.nanmin(np.abs(ds_s3.lat_01 - lat_avg)))
    LON = ds_s3.lon_01[ii]
    LON[LON>180] = LON[LON>180]-360
    if ROI[1] - 1 > LON > ROI[0] + 1:
        plt.annotate('_'.join(os.path.basename(os.path.dirname(s3_file)).split('_')[0:8]), (ds_s3.lon_01[ii] + 0.25, ds_s3.lat_01[ii]),
                     fontsize=12, rotation=60, color='k', zorder=10000, backgroundcolor=(1.0, 1.0, 1.0, 0.3))
    ds_s3.close()

plt.show()











# select input file
input_file = os.path.join(download_dir, 'S3B_SR_2_WAT____20231104T112652_20231104T121252_20231130T031212_2760_086_023______MAR_O_NT_005.SEN3', 'enhanced_measurement.nc')

# open input file, select only the part we were looking at above, using this time the "20Hz" data since waveforms are only provided with this resolution
ds = xr.open_dataset(input_file)
ds_subset = ds.sel(time_20_ku=( (ds.lat_20_ku > ROI[2] ) & (ds.lat_20_ku < ROI[3])))
ds.close()





ds_subset





# read the variables
echo_sample_ind = ds_subset['echo_sample_ind']
waveform_20_ku = ds_subset['waveform_20_ku']
swh_ocean_20_ku = ds_subset['swh_ocean_20_ku']
swh_ocean_01_ku = ds_subset['swh_ocean_01_ku']
lat20 = ds_subset['lat_20_ku']
lat1 = ds_subset['lat_01']

# plot SWH at 20 Hz - note that those data are much noisier than 1 Hz ones (NB. 1Hz data have not been extracted over only part of the track)
print('max swh 20 Hz ku', np.max(swh_ocean_20_ku).values)
print('max swh 1 Hz ku', np.max(swh_ocean_01_ku).values)





fig = plt.figure(figsize=(20, 8), dpi=300)
plt.xlim(ROI[2], ROI[3])
p1, = plt.plot(lat20, swh_ocean_20_ku)
p2, = plt.plot(lat1, swh_ocean_01_ku)
plt.xlabel("Latitude")
plt.ylabel("Significant wave height [m]")
plt.legend([p1, p2],["20 Hz", "1 Hz"], frameon=False);





waveform_20_ku_max = waveform_20_ku.sel(time_20_ku=(swh_ocean_20_ku == np.max(swh_ocean_20_ku)))
waveform_20_ku_min = waveform_20_ku.sel(time_20_ku=(swh_ocean_20_ku == np.min(swh_ocean_20_ku)))
wvf_min = waveform_20_ku_min[0,:]
wvf_max = waveform_20_ku_max[0,:]


fig = plt.figure(figsize=(20, 8), dpi=300)
p1, = plt.plot(echo_sample_ind, wvf_min)
p2, = plt.plot(echo_sample_ind, wvf_max)
plt.xlabel("Power")
plt.ylabel("Bins")
plt.legend([p1, p2],["low SWH", "high SWH"], frameon=False);














# Default location expected by the copernicusmarine package
copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')

# Create it only if it does not already exists
if not copernicus_marine_credentials_file.is_file():
    copernicusmarine.login()





ds_L4 = copernicusmarine.open_dataset(
               dataset_id=CMEMS_productID,
               variables=CMEMS_variables,
               minimum_longitude=ROI[0],
               maximum_longitude=ROI[1],
               minimum_latitude=ROI[2],
               maximum_latitude=ROI[3],
               start_datetime=start.strftime("%Y-%m-%dT00:00:00.000Z"),
               end_datetime=end.strftime("%Y-%m-%dT23:59:59.000Z"))





ds_L4











viewer = Viewer(
    server_config={
        "Styles": [
            {
                "Identifier": "SWH",
                "ColorMappings": {
                    "VHM0": {"ValueRange": [0, 12], "ColorBar": "Spectral_r"}
                },
            }        
        ]
    }
)





viewer.add_dataset(ds_L4, title="SWH operational", style="SWH");
viewer.show()









