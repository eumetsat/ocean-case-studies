{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../frameworks/img/EU-Copernicus-EUM-WEKEO_banner_logo_UNOD_banner.png' align='right' width='100%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../Index.ipynb\"><< Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2022 EUMETSAT <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** B. Loveday (Innoflair UG / EUMETSAT), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean case studies</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "There are no prerequisite notebooks for this module. <br><br>\n",
    "\n",
    "Users should refer to the following case study for more contextual information:\n",
    "- **[Coastal deoxygenation: South African red tides](https://www.eumetsat.int/LINKS!!)**  <<FIX\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red tides in South African Waters\n",
    "<font color=\"#138D75\">**UN Ocean Decade Challenge 3: Sustainably feed the global population**</font>\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Product Description  | Data Store collection ID|  WEkEO HDA ID | Product Navigator |\n",
    "|:--------------------:|:-----------------------:|:-------------:|:-----------------:|\n",
    "| Sentinel-3 OLCI level-2 Full resolution | EO:EUM:DAT:0407 | EO:EUM:DAT:SENTINEL-3:OL_2_WFR___ | [link](https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:OL_2_WFR___NTC?query=OLCI&filter=satellite__Sentinel-3&filter=instrument__OLCI&filter=processingLevel__Level%202%20Data&s=advanced) |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know how to ;\n",
    "* extract OLCI spectra over the red tide on South Africa's west coast on February 26th, 2022\n",
    "* plot OLCI spectra over a given region\n",
    "\n",
    "\n",
    "### Outline\n",
    "\n",
    "TODO: REPLACE RGB WITH CHL_NN MINIMAP with lat/lon\n",
    "\n",
    "This code will replicate figure ??? from this case study; **[Coastal deoxygenation: South African red tides](https://www.eumetsat.int/LINKS!!)**  <<FIX\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOC_TOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "    \n",
    " 1. [Acquiring OLCI data](#section1)\n",
    " 2. [Reading OLCI spectral data](#section2)\n",
    " 3. [Plotting OLCI spectra for specific points](#section3)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import eumdac\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import eumartools\n",
    "\n",
    "from bokeh.io import output_notebook, show, export_png\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import HoverTool, Range1d, LinearAxis\n",
    "from bokeh.layouts import row\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Acquiring OLCI data\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a directory for our download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a download directory for our OLCI products\n",
    "download_dir = os.path.join(os.getcwd(), \"products\")\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to specify the collection_id for OLCI Level-2 full resolution products (as specified in the \"Data Used\" section above), as well as the product that we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = 'EO:EUM:DAT:0407'\n",
    "product_list = ['S3B_OL_2_WFR____20220226T080620_20220226T080920_20220227T190632_0179_063_092_3420_MAR_O_NT_003.SEN3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to allow us to download data from the Data Store via API, we need to provide our credentials. To do this, we need to create a file called `.eumdac_credentials` in our home directory. For most computer systems the home directory can be found at the path \\user\\username, /users/username, or /home/username depending on your operating system.\n",
    "\n",
    "In this file we need to add the following information exactly as follows;\n",
    "\n",
    "```\n",
    "{\n",
    "\"consumer_key\": \"<your_consumer_key>\",\n",
    "\"consumer_secret\": \"<your_consumer_secret>\"\n",
    "}\n",
    "```\n",
    "\n",
    "You must replace `<your_consumer_key>` and `<your_consumer_secret>` with the information you extract from https://api.eumetsat.int/api-key/. You will need a [EUMETSAT Earth Observation Portal account](https://eoportal.eumetsat.int/) to access this link, and in order to see the information you must click the \"Show hidden fields\" button at the bottom of the page.\n",
    "\n",
    "*Note: your key and secret are permanent, so you only need to do this once, but you should take care to never share them*\n",
    "\n",
    "Once you have done this, you can read in your credentials using the commands in the following cell. These will be used to generate a time-limited token, which will refresh itself when it expires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.expanduser(\"~\"),'.eumdac_credentials')) as json_file:\n",
    "    credentials = json.load(json_file)\n",
    "    token = eumdac.AccessToken((credentials['consumer_key'], credentials['consumer_secret']))\n",
    "    print(f\"This token '{token}' expires {token.expiration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a token, we can ask the Data Store for our specified product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = eumdac.DataStore(token)\n",
    "selected_product = datastore.get_product(product_id=product_list[0], collection_id=collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download this product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with selected_product.open() as fsrc, open(os.path.join(download_dir, fsrc.name), mode='wb') as fdst:\n",
    "    print(f'Downloading {fsrc.name}')\n",
    "    shutil.copyfileobj(fsrc, fdst)\n",
    "    print(f'Download of product {fsrc.name} finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we will unzip the product and tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(fdst.name, 'r') as zip_ref:\n",
    "    for file in zip_ref.namelist():\n",
    "        if file.startswith(str(selected_product)):\n",
    "            zip_ref.extract(file, download_dir)\n",
    "    print(f'Unzipping of product {selected_product} finished.')\n",
    "os.remove(fdst.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Reading OLCI spectral data\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAFE_directory = glob.glob(os.path.join(download_dir,'*.SEN3'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data dictionary\n",
    "data = {\n",
    "        'pt1':{\n",
    "        'band_names': [],\n",
    "        'band_centres': [],\n",
    "        'band_widths': [],\n",
    "        'means': [],\n",
    "        'uppers': [],\n",
    "        'lowers': [],\n",
    "        'errs': []},\n",
    "\n",
    "        'pt2':{\n",
    "        'band_names': [],\n",
    "        'band_centres': [],\n",
    "        'band_widths': [],\n",
    "        'means': [],\n",
    "        'uppers': [],\n",
    "        'lowers': [],\n",
    "        'errs': []},\n",
    "\n",
    "        'pt3':{\n",
    "        'band_names': [],\n",
    "        'band_centres': [],\n",
    "        'band_widths': [],\n",
    "        'means': [],\n",
    "        'uppers': [],\n",
    "        'lowers': [],\n",
    "        'errs': []}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(os.path.join(SAFE_directory,'xfdumanifest.xml'))\n",
    "root = tree.getroot()\n",
    "match = {\"sentinel3\":\"http://www.esa.int/safe/sentinel/sentinel-3/1.0\"}\n",
    "data['pt1'][\"band_names\"] = [item.attrib[\"name\"] for item in root.findall('.//sentinel3:band', match)]\n",
    "data['pt1'][\"band_centres\"] = [float(item.text) for item in root.findall('.//sentinel3:centralWavelength', match)]\n",
    "data['pt1'][\"band_widths\"] = [float(item.text) for item in root.findall('.//sentinel3:bandwidth', match)]\n",
    "\n",
    "data['pt2'][\"band_names\"] = data['pt1'][\"band_names\"]\n",
    "data['pt2'][\"band_centres\"] = data['pt1'][\"band_centres\"]\n",
    "data['pt2'][\"band_widths\"] = data['pt1'][\"band_widths\"]\n",
    "\n",
    "data['pt3'][\"band_names\"] = data['pt1'][\"band_names\"]\n",
    "data['pt3'][\"band_centres\"] = data['pt1'][\"band_centres\"]\n",
    "data['pt3'][\"band_widths\"] = data['pt1'][\"band_widths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes area average\n",
    "points = {\n",
    "        'pt1':{\n",
    "        'lons': [18.20, 18.25, 18.25, 18.20, 18.20],\n",
    "        'lats': [-32.15, -32.15, -32.10, -32.10, -32.15]},\n",
    "\n",
    "        'pt2':{\n",
    "        'lons': [18.00, 18.05, 18.05, 18.00, 18.00],\n",
    "        'lats': [-32.25, -32.25, -32.20, -32.20, -32.25]},\n",
    "\n",
    "        'pt3':{\n",
    "        'lons': [16.50, 16.55, 16.55, 16.50, 16.50],\n",
    "        'lats': [-31.95, -31.95, -31.90, -31.90, -31.95]}\n",
    "        }\n",
    "\n",
    "# for minimap plotting only\n",
    "grid_reduce = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_file = os.path.join(SAFE_directory,'geo_coordinates.nc')\n",
    "geo_vars = xr.open_dataset(geo_file)\n",
    "lon = geo_vars.longitude.data[::grid_reduce, ::grid_reduce]\n",
    "lat = geo_vars.latitude.data[::grid_reduce, ::grid_reduce]\n",
    "geo_vars.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading:  Oa01_reflectance for pt1\n",
      "Reading:  Oa01_reflectance_err for pt1\n",
      "Reading:  Oa02_reflectance for pt1\n",
      "Reading:  Oa02_reflectance_err for pt1\n",
      "Reading:  Oa03_reflectance for pt1\n",
      "Reading:  Oa03_reflectance_err for pt1\n",
      "Reading:  Oa04_reflectance for pt1\n",
      "Reading:  Oa04_reflectance_err for pt1\n",
      "Reading:  Oa05_reflectance for pt1\n",
      "Reading:  Oa05_reflectance_err for pt1\n",
      "Reading:  Oa06_reflectance for pt1\n",
      "Reading:  Oa06_reflectance_err for pt1\n",
      "Reading:  Oa07_reflectance for pt1\n",
      "Reading:  Oa07_reflectance_err for pt1\n",
      "Reading:  Oa08_reflectance for pt1\n",
      "Reading:  Oa08_reflectance_err for pt1\n",
      "Reading:  Oa09_reflectance for pt1\n",
      "Reading:  Oa09_reflectance_err for pt1\n",
      "Reading:  Oa10_reflectance for pt1\n",
      "Reading:  Oa10_reflectance_err for pt1\n",
      "Reading:  Oa11_reflectance for pt1\n",
      "Reading:  Oa11_reflectance_err for pt1\n",
      "Reading:  Oa12_reflectance for pt1\n",
      "Reading:  Oa12_reflectance_err for pt1\n",
      "Reading:  Oa16_reflectance for pt1\n",
      "Reading:  Oa16_reflectance_err for pt1\n",
      "Reading:  Oa17_reflectance for pt1\n",
      "Reading:  Oa17_reflectance_err for pt1\n",
      "Reading:  Oa18_reflectance for pt1\n",
      "Reading:  Oa18_reflectance_err for pt1\n",
      "Reading:  Oa21_reflectance for pt1\n",
      "Reading:  Oa21_reflectance_err for pt1\n",
      "Reading:  Oa01_reflectance for pt2\n",
      "Reading:  Oa01_reflectance_err for pt2\n",
      "Reading:  Oa02_reflectance for pt2\n",
      "Reading:  Oa02_reflectance_err for pt2\n",
      "Reading:  Oa03_reflectance for pt2\n",
      "Reading:  Oa03_reflectance_err for pt2\n",
      "Reading:  Oa04_reflectance for pt2\n",
      "Reading:  Oa04_reflectance_err for pt2\n",
      "Reading:  Oa05_reflectance for pt2\n",
      "Reading:  Oa05_reflectance_err for pt2\n",
      "Reading:  Oa06_reflectance for pt2\n",
      "Reading:  Oa06_reflectance_err for pt2\n",
      "Reading:  Oa07_reflectance for pt2\n",
      "Reading:  Oa07_reflectance_err for pt2\n",
      "Reading:  Oa08_reflectance for pt2\n",
      "Reading:  Oa08_reflectance_err for pt2\n",
      "Reading:  Oa09_reflectance for pt2\n",
      "Reading:  Oa09_reflectance_err for pt2\n",
      "Reading:  Oa10_reflectance for pt2\n",
      "Reading:  Oa10_reflectance_err for pt2\n",
      "Reading:  Oa11_reflectance for pt2\n",
      "Reading:  Oa11_reflectance_err for pt2\n",
      "Reading:  Oa12_reflectance for pt2\n",
      "Reading:  Oa12_reflectance_err for pt2\n",
      "Reading:  Oa16_reflectance for pt2\n",
      "Reading:  Oa16_reflectance_err for pt2\n",
      "Reading:  Oa17_reflectance for pt2\n",
      "Reading:  Oa17_reflectance_err for pt2\n",
      "Reading:  Oa18_reflectance for pt2\n",
      "Reading:  Oa18_reflectance_err for pt2\n",
      "Reading:  Oa21_reflectance for pt2\n",
      "Reading:  Oa21_reflectance_err for pt2\n",
      "Reading:  Oa01_reflectance for pt3\n",
      "Reading:  Oa01_reflectance_err for pt3\n",
      "Reading:  Oa02_reflectance for pt3\n",
      "Reading:  Oa02_reflectance_err for pt3\n",
      "Reading:  Oa03_reflectance for pt3\n",
      "Reading:  Oa03_reflectance_err for pt3\n",
      "Reading:  Oa04_reflectance for pt3\n",
      "Reading:  Oa04_reflectance_err for pt3\n",
      "Reading:  Oa05_reflectance for pt3\n",
      "Reading:  Oa05_reflectance_err for pt3\n",
      "Reading:  Oa06_reflectance for pt3\n",
      "Reading:  Oa06_reflectance_err for pt3\n",
      "Reading:  Oa07_reflectance for pt3\n",
      "Reading:  Oa07_reflectance_err for pt3\n",
      "Reading:  Oa08_reflectance for pt3\n",
      "Reading:  Oa08_reflectance_err for pt3\n",
      "Reading:  Oa09_reflectance for pt3\n",
      "Reading:  Oa09_reflectance_err for pt3\n",
      "Reading:  Oa10_reflectance for pt3\n",
      "Reading:  Oa10_reflectance_err for pt3\n",
      "Reading:  Oa11_reflectance for pt3\n",
      "Reading:  Oa11_reflectance_err for pt3\n",
      "Reading:  Oa12_reflectance for pt3\n",
      "Reading:  Oa12_reflectance_err for pt3\n",
      "Reading:  Oa16_reflectance for pt3\n",
      "Reading:  Oa16_reflectance_err for pt3\n",
      "Reading:  Oa17_reflectance for pt3\n",
      "Reading:  Oa17_reflectance_err for pt3\n",
      "Reading:  Oa18_reflectance for pt3\n",
      "Reading:  Oa18_reflectance_err for pt3\n",
      "Reading:  Oa21_reflectance for pt3\n",
      "Reading:  Oa21_reflectance_err for pt3\n"
     ]
    }
   ],
   "source": [
    "RGB_dict = {}\n",
    "exs = []\n",
    "eys = []\n",
    "for point in points:\n",
    "    # read everything we need from netcdf: open all the files at once\n",
    "    band_vars = xr.open_mfdataset(glob.glob(os.path.join(SAFE_directory,'Oa*.nc')))\n",
    "    ex, ey, mask = eumartools.subset_image(lon, lat, points[point]['lons'], points[point]['lats'])\n",
    "    mask = mask.T\n",
    "\n",
    "    exs.append(ex)\n",
    "    eys.append(ey)\n",
    "    \n",
    "    for band_var in band_vars:\n",
    "        print(f\"Reading:  {band_var} for {point}\")\n",
    "        var = band_vars[band_var].data[::grid_reduce, ::grid_reduce]*mask\n",
    "        if \"_err\" in band_var:\n",
    "            data[point][\"errs\"].append(np.array(np.nanmean(var)))\n",
    "        else:\n",
    "            data[point][\"means\"].append(np.array(np.nanmean(var)))\n",
    "            data[point][\"uppers\"].append(np.array(np.nanmean(var) + np.nanstd(var)))\n",
    "            data[point][\"lowers\"].append(np.array(np.nanmean(var) - np.nanstd(var)))\n",
    "\n",
    "            # this is just to build our quick minimap\n",
    "            if \"pt1\" in point:\n",
    "                if \"Oa08_reflectance\" in band_var or \"Oa06_reflectance\" in band_var or \"Oa02_reflectance\" in band_var:\n",
    "                    RGB_dict[band_var] = band_vars[band_var].data[::grid_reduce, ::grid_reduce]\n",
    "\n",
    "    band_vars.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in Pandas dataframes for convenience\n",
    "df = []\n",
    "for point in points:\n",
    "    data[point][\"low_band\"]  = [a-b for a,b in zip(data[point][\"band_centres\"], data[point][\"band_widths\"])]\n",
    "    data[point][\"high_band\"] = [a+b for a,b in zip(data[point][\"band_centres\"], data[point][\"band_widths\"])]\n",
    "    data[point][\"low_errs\"]  = [a-b for a,b in zip(data[point][\"means\"], data[point][\"errs\"])]\n",
    "    data[point][\"high_errs\"] = [a+b for a,b in zip(data[point][\"means\"], data[point][\"errs\"])]\n",
    "    df.append(pd.DataFrame(data[point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Plotting OLCI spectra for specific points\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build minimap\n",
    "rgb = np.dstack((RGB_dict[\"Oa08_reflectance\"],\n",
    "                 RGB_dict[\"Oa06_reflectance\"],\n",
    "                 RGB_dict[\"Oa02_reflectance\"]))\n",
    "\n",
    "rgb = eumartools.normalise_image(rgb, unhitch=True)\n",
    "rgb = eumartools.truncate_image(rgb, min_percentile=1, max_percentile=80)\n",
    "rgb = eumartools.histogram_image(rgb, nbins=512)\n",
    "\n",
    "# make image array\n",
    "img = np.empty((np.shape(rgb)[0], np.shape(rgb)[1]), dtype=np.uint32)\n",
    "view = img.view(dtype=np.uint8).reshape((np.shape(rgb)[0], np.shape(rgb)[1], 4))\n",
    "for ii in range(np.shape(rgb)[-1]):\n",
    "    view[:, :, ii] = rgb[:,:,ii]*255\n",
    "# add alpha\n",
    "view[:, :, 3] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new plot\n",
    "hover = HoverTool(tooltips=[(\"(wavelength, rad/ref)\", \"($x, $y)\")])\n",
    "\n",
    "# spectra\n",
    "p = figure(plot_width=1000, plot_height=1000,\n",
    "           title=\"OLCI reflectances over selected points\",\n",
    "           y_range=(0, max(df[0][\"uppers\"])*1.1),\n",
    "           tools=[hover, 'pan', 'box_zoom', 'save', 'reset'],\n",
    "           toolbar_location=\"below\")\n",
    "\n",
    "p.title.align = 'center'\n",
    "p.title.text_font_size = '14pt'\n",
    "p.xaxis.axis_label = r\"$$ \\text{Wavelength } [nm] $$\"\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label = r\"$$\\color{black} \\text{reflectance } [sr^{-1}] $$\"\n",
    "\n",
    "for sr, c in zip(df,['red', 'blue', 'black']):\n",
    "    p.varea(source=sr, x=\"band_centres\", y1=\"lowers\", y2=\"uppers\", alpha=0.5, color=c)\n",
    "    p.line(source=sr, x=\"band_centres\", y=\"means\", line_width=2, color=c)\n",
    "    p.circle(source=sr, x=\"band_centres\", y=\"means\", line_color=\"black\", fill_color=c, size=4)\n",
    "    p.segment(source=sr, x0=\"low_band\", y0=\"means\", x1=\"high_band\", y1=\"means\", line_color=\"black\")\n",
    "    p.yaxis.axis_label_text_color = c\n",
    "    p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "# minimap\n",
    "m = figure(plot_width=500, plot_height=500, toolbar_location=\"below\")\n",
    "m.image_rgba(image=[np.flipud(img)], x=0, y=0, dw=np.shape(rgb)[1], dh=np.shape(rgb)[0])\n",
    "\n",
    "m.line(x=exs[0], y=[np.shape(img)[0] - i for i in eys[0]], color=\"red\", line_width=2)\n",
    "m.line(x=exs[1], y=[np.shape(img)[0] - i for i in eys[1]], color=\"blue\", line_width=2)\n",
    "m.line(x=exs[2], y=[np.shape(img)[0] - i for i in eys[2]], color=\"black\", line_width=2)\n",
    "\n",
    "m.axis.visible = False ; m.xgrid.visible = False ; m.ygrid.visible = False\n",
    "\n",
    "show(row(p, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/ocean\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:Copernicus.training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
